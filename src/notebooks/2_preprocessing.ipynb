{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "664f2f67-d217-4a9c-b794-fa7fecd115a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # disable warnings\n",
    "\n",
    "from os import getcwd\n",
    "from os.path import join, abspath, pardir, exists\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle, json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "# scipy\n",
    "from scipy.stats import ttest_ind, chi2_contingency, boxcox, skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.impute import KNNImputer, SimpleImputer, MissingIndicator\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.pipeline import FeatureUnion, make_pipeline, Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import make_column_selector, make_column_transformer, make_column_transformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "\n",
    "# statsmodel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# IPython\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83b4df",
   "metadata": {},
   "source": [
    "##### Config settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4894fe-4fc0-4580-b2df-275bbdfb82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = abspath(join(join(getcwd(), pardir), pardir))\n",
    "data_dir = join(parent_dir, \"data\")\n",
    "data_file = join(data_dir, \"speed_dating.csv\")\n",
    "\n",
    "# For IPython\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # To show all output after each cell execution (instead of the last output)\n",
    "\n",
    "# For pandas\n",
    "\n",
    "pd.options.display.max_columns = 200 # display upto 200 columns (instead of default 20)\n",
    "pd.options.display.max_rows = 200 # display upto 200 rows (instead of default 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627281a6",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46177fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save model as a pickle file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "def load_model(file_path: str):\n",
    "    \"\"\"\n",
    "    Load model from a pickle file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def dataframe_to_csv(df: pd.DataFrame, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save dataframe as .csv file\n",
    "    \"\"\"\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923cfea",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Data preprocessing is the first machine learning step in which we transform raw data obtained from various sources into a usable format to implement accurate machine learning models. \n",
    "\n",
    "In a real-world data science project, data preprocessing is one of the most important things, and it is one of the common factors of success of a model, i.e., if there is correct data preprocessing and feature engineering, that model is more likely to produce noticeably better results as compared to a model for which data is not well preprocessed.\n",
    "\n",
    "That's why you may have heard that 80% of a data scientist’s time goes into data preprocessing and 20% of the time for model building. This isn’t false and is actually the case.\n",
    "\n",
    "##### Typical Preprocessing Steps\n",
    "\n",
    "Below mentioned are the typical data preprocessing steps:\n",
    "\n",
    "- Basic checking of data: Check data types and see if you have bad data\n",
    "- Refractor/Change columns names (if needed)\n",
    "- Check for imbalance data\n",
    "- Split your dataset into train and test datasets (stratified sampling in case of imbalance data)\n",
    "- Check for missing data\n",
    "- Removal of noise from the dataset\n",
    "- Imputation of missing values\n",
    "- Outlier detection and removal\n",
    "- Feature Selection\n",
    "- Create new and improved features (if needed)\n",
    "- Perform new feature imputation if needed\n",
    "- Normalization (transform all features' values b/w 0 & 1 )\n",
    "- Standardization (transform all features so they have a mean 0 and standard deviation 1)\n",
    "- Scaling the features\n",
    "- Binning continuous data (if needed)\n",
    "- Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18ae3627-784c-4550-8dc4-ffd94bcbcbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race_o</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>pf_o_fun</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>pf_o_sha</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>like_o</th>\n",
       "      <th>prob_o</th>\n",
       "      <th>met_o</th>\n",
       "      <th>age</th>\n",
       "      <th>field</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>undergra</th>\n",
       "      <th>mn_sat</th>\n",
       "      <th>tuition</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>from</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>income</th>\n",
       "      <th>goal</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>career</th>\n",
       "      <th>career_c</th>\n",
       "      <th>sports</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>expnum</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr4_1</th>\n",
       "      <th>sinc4_1</th>\n",
       "      <th>intel4_1</th>\n",
       "      <th>fun4_1</th>\n",
       "      <th>amb4_1</th>\n",
       "      <th>shar4_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>attr5_1</th>\n",
       "      <th>sinc5_1</th>\n",
       "      <th>intel5_1</th>\n",
       "      <th>fun5_1</th>\n",
       "      <th>amb5_1</th>\n",
       "      <th>dec</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "      <th>match_es</th>\n",
       "      <th>attr1_s</th>\n",
       "      <th>sinc1_s</th>\n",
       "      <th>intel1_s</th>\n",
       "      <th>fun1_s</th>\n",
       "      <th>amb1_s</th>\n",
       "      <th>shar1_s</th>\n",
       "      <th>attr3_s</th>\n",
       "      <th>sinc3_s</th>\n",
       "      <th>intel3_s</th>\n",
       "      <th>fun3_s</th>\n",
       "      <th>amb3_s</th>\n",
       "      <th>satis_2</th>\n",
       "      <th>length</th>\n",
       "      <th>numdat_2</th>\n",
       "      <th>attr7_2</th>\n",
       "      <th>sinc7_2</th>\n",
       "      <th>intel7_2</th>\n",
       "      <th>fun7_2</th>\n",
       "      <th>amb7_2</th>\n",
       "      <th>shar7_2</th>\n",
       "      <th>attr1_2</th>\n",
       "      <th>sinc1_2</th>\n",
       "      <th>intel1_2</th>\n",
       "      <th>fun1_2</th>\n",
       "      <th>amb1_2</th>\n",
       "      <th>shar1_2</th>\n",
       "      <th>attr4_2</th>\n",
       "      <th>sinc4_2</th>\n",
       "      <th>intel4_2</th>\n",
       "      <th>fun4_2</th>\n",
       "      <th>amb4_2</th>\n",
       "      <th>shar4_2</th>\n",
       "      <th>attr2_2</th>\n",
       "      <th>sinc2_2</th>\n",
       "      <th>intel2_2</th>\n",
       "      <th>fun2_2</th>\n",
       "      <th>amb2_2</th>\n",
       "      <th>shar2_2</th>\n",
       "      <th>attr3_2</th>\n",
       "      <th>sinc3_2</th>\n",
       "      <th>intel3_2</th>\n",
       "      <th>fun3_2</th>\n",
       "      <th>amb3_2</th>\n",
       "      <th>attr5_2</th>\n",
       "      <th>sinc5_2</th>\n",
       "      <th>intel5_2</th>\n",
       "      <th>fun5_2</th>\n",
       "      <th>amb5_2</th>\n",
       "      <th>you_call</th>\n",
       "      <th>them_cal</th>\n",
       "      <th>date_3</th>\n",
       "      <th>numdat_3</th>\n",
       "      <th>num_in_3</th>\n",
       "      <th>attr1_3</th>\n",
       "      <th>sinc1_3</th>\n",
       "      <th>intel1_3</th>\n",
       "      <th>fun1_3</th>\n",
       "      <th>amb1_3</th>\n",
       "      <th>shar1_3</th>\n",
       "      <th>attr7_3</th>\n",
       "      <th>sinc7_3</th>\n",
       "      <th>intel7_3</th>\n",
       "      <th>fun7_3</th>\n",
       "      <th>amb7_3</th>\n",
       "      <th>shar7_3</th>\n",
       "      <th>attr4_3</th>\n",
       "      <th>sinc4_3</th>\n",
       "      <th>intel4_3</th>\n",
       "      <th>fun4_3</th>\n",
       "      <th>amb4_3</th>\n",
       "      <th>shar4_3</th>\n",
       "      <th>attr2_3</th>\n",
       "      <th>sinc2_3</th>\n",
       "      <th>intel2_3</th>\n",
       "      <th>fun2_3</th>\n",
       "      <th>amb2_3</th>\n",
       "      <th>shar2_3</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>69,487.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>22.22</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>69,487.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>22.22</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>69,487.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>22.22</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>69,487.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>22.22</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>69,487.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>22.22</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7   \n",
       "\n",
       "   partner   pid  match  int_corr  samerace  age_o  race_o  pf_o_att  \\\n",
       "0        1  11.0      0      0.14         0   27.0     2.0      35.0   \n",
       "1        2  12.0      0      0.54         0   22.0     2.0      60.0   \n",
       "2        3  13.0      1      0.16         1   22.0     4.0      19.0   \n",
       "3        4  14.0      1      0.61         0   23.0     2.0      30.0   \n",
       "4        5  15.0      1      0.21         0   24.0     3.0      30.0   \n",
       "\n",
       "   pf_o_sin  pf_o_int  pf_o_fun  pf_o_amb  pf_o_sha  dec_o  attr_o  sinc_o  \\\n",
       "0      20.0      20.0      20.0       0.0       5.0      0     6.0     8.0   \n",
       "1       0.0       0.0      40.0       0.0       0.0      0     7.0     8.0   \n",
       "2      18.0      19.0      18.0      14.0      12.0      1    10.0    10.0   \n",
       "3       5.0      15.0      40.0       5.0       5.0      1     7.0     8.0   \n",
       "4      10.0      20.0      10.0      10.0      20.0      1     8.0     7.0   \n",
       "\n",
       "   intel_o  fun_o  amb_o  shar_o  like_o  prob_o  met_o   age field  field_cd  \\\n",
       "0      8.0    8.0    8.0     6.0     7.0     4.0    2.0  21.0   Law       1.0   \n",
       "1     10.0    7.0    7.0     5.0     8.0     4.0    2.0  21.0   Law       1.0   \n",
       "2     10.0   10.0   10.0    10.0    10.0    10.0    1.0  21.0   Law       1.0   \n",
       "3      9.0    8.0    9.0     8.0     7.0     7.0    2.0  21.0   Law       1.0   \n",
       "4      9.0    6.0    9.0     7.0     8.0     6.0    2.0  21.0   Law       1.0   \n",
       "\n",
       "  undergra mn_sat tuition  race  imprace  imprelig     from zipcode  \\\n",
       "0      NaN    NaN     NaN   4.0      2.0       4.0  Chicago  60,521   \n",
       "1      NaN    NaN     NaN   4.0      2.0       4.0  Chicago  60,521   \n",
       "2      NaN    NaN     NaN   4.0      2.0       4.0  Chicago  60,521   \n",
       "3      NaN    NaN     NaN   4.0      2.0       4.0  Chicago  60,521   \n",
       "4      NaN    NaN     NaN   4.0      2.0       4.0  Chicago  60,521   \n",
       "\n",
       "      income  goal  date  go_out  career  career_c  sports  tvsports  \\\n",
       "0  69,487.00   2.0   7.0     1.0  lawyer       NaN     9.0       2.0   \n",
       "1  69,487.00   2.0   7.0     1.0  lawyer       NaN     9.0       2.0   \n",
       "2  69,487.00   2.0   7.0     1.0  lawyer       NaN     9.0       2.0   \n",
       "3  69,487.00   2.0   7.0     1.0  lawyer       NaN     9.0       2.0   \n",
       "4  69,487.00   2.0   7.0     1.0  lawyer       NaN     9.0       2.0   \n",
       "\n",
       "   exercise  dining  museums  art  hiking  gaming  clubbing  reading   tv  \\\n",
       "0       8.0     9.0      1.0  1.0     5.0     1.0       5.0      6.0  9.0   \n",
       "1       8.0     9.0      1.0  1.0     5.0     1.0       5.0      6.0  9.0   \n",
       "2       8.0     9.0      1.0  1.0     5.0     1.0       5.0      6.0  9.0   \n",
       "3       8.0     9.0      1.0  1.0     5.0     1.0       5.0      6.0  9.0   \n",
       "4       8.0     9.0      1.0  1.0     5.0     1.0       5.0      6.0  9.0   \n",
       "\n",
       "   theater  movies  concerts  music  shopping  yoga  exphappy  expnum  \\\n",
       "0      1.0    10.0      10.0    9.0       8.0   1.0       3.0     2.0   \n",
       "1      1.0    10.0      10.0    9.0       8.0   1.0       3.0     2.0   \n",
       "2      1.0    10.0      10.0    9.0       8.0   1.0       3.0     2.0   \n",
       "3      1.0    10.0      10.0    9.0       8.0   1.0       3.0     2.0   \n",
       "4      1.0    10.0      10.0    9.0       8.0   1.0       3.0     2.0   \n",
       "\n",
       "   attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1  attr4_1  sinc4_1  \\\n",
       "0     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "1     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "2     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "3     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "4     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "\n",
       "   intel4_1  fun4_1  amb4_1  shar4_1  attr2_1  sinc2_1  intel2_1  fun2_1  \\\n",
       "0       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "1       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "2       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "3       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "4       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "\n",
       "   amb2_1  shar2_1  attr3_1  sinc3_1  fun3_1  intel3_1  amb3_1  attr5_1  \\\n",
       "0     5.0      5.0      6.0      8.0     8.0       8.0     7.0      NaN   \n",
       "1     5.0      5.0      6.0      8.0     8.0       8.0     7.0      NaN   \n",
       "2     5.0      5.0      6.0      8.0     8.0       8.0     7.0      NaN   \n",
       "3     5.0      5.0      6.0      8.0     8.0       8.0     7.0      NaN   \n",
       "4     5.0      5.0      6.0      8.0     8.0       8.0     7.0      NaN   \n",
       "\n",
       "   sinc5_1  intel5_1  fun5_1  amb5_1  dec  attr  sinc  intel  fun  amb  shar  \\\n",
       "0      NaN       NaN     NaN     NaN    1   6.0   9.0    7.0  7.0  6.0   5.0   \n",
       "1      NaN       NaN     NaN     NaN    1   7.0   8.0    7.0  8.0  5.0   6.0   \n",
       "2      NaN       NaN     NaN     NaN    1   5.0   8.0    9.0  8.0  5.0   7.0   \n",
       "3      NaN       NaN     NaN     NaN    1   7.0   6.0    8.0  7.0  6.0   8.0   \n",
       "4      NaN       NaN     NaN     NaN    1   5.0   6.0    7.0  7.0  6.0   6.0   \n",
       "\n",
       "   like  prob  met  match_es  attr1_s  sinc1_s  intel1_s  fun1_s  amb1_s  \\\n",
       "0   7.0   6.0  2.0       4.0      NaN      NaN       NaN     NaN     NaN   \n",
       "1   7.0   5.0  1.0       4.0      NaN      NaN       NaN     NaN     NaN   \n",
       "2   7.0   NaN  1.0       4.0      NaN      NaN       NaN     NaN     NaN   \n",
       "3   7.0   6.0  2.0       4.0      NaN      NaN       NaN     NaN     NaN   \n",
       "4   6.0   6.0  2.0       4.0      NaN      NaN       NaN     NaN     NaN   \n",
       "\n",
       "   shar1_s  attr3_s  sinc3_s  intel3_s  fun3_s  amb3_s  satis_2  length  \\\n",
       "0      NaN      NaN      NaN       NaN     NaN     NaN      6.0     2.0   \n",
       "1      NaN      NaN      NaN       NaN     NaN     NaN      6.0     2.0   \n",
       "2      NaN      NaN      NaN       NaN     NaN     NaN      6.0     2.0   \n",
       "3      NaN      NaN      NaN       NaN     NaN     NaN      6.0     2.0   \n",
       "4      NaN      NaN      NaN       NaN     NaN     NaN      6.0     2.0   \n",
       "\n",
       "   numdat_2  attr7_2  sinc7_2  intel7_2  fun7_2  amb7_2  shar7_2  attr1_2  \\\n",
       "0       1.0      NaN      NaN       NaN     NaN     NaN      NaN    19.44   \n",
       "1       1.0      NaN      NaN       NaN     NaN     NaN      NaN    19.44   \n",
       "2       1.0      NaN      NaN       NaN     NaN     NaN      NaN    19.44   \n",
       "3       1.0      NaN      NaN       NaN     NaN     NaN      NaN    19.44   \n",
       "4       1.0      NaN      NaN       NaN     NaN     NaN      NaN    19.44   \n",
       "\n",
       "   sinc1_2  intel1_2  fun1_2  amb1_2  shar1_2  attr4_2  sinc4_2  intel4_2  \\\n",
       "0    16.67     13.89   22.22   11.11    16.67      NaN      NaN       NaN   \n",
       "1    16.67     13.89   22.22   11.11    16.67      NaN      NaN       NaN   \n",
       "2    16.67     13.89   22.22   11.11    16.67      NaN      NaN       NaN   \n",
       "3    16.67     13.89   22.22   11.11    16.67      NaN      NaN       NaN   \n",
       "4    16.67     13.89   22.22   11.11    16.67      NaN      NaN       NaN   \n",
       "\n",
       "   fun4_2  amb4_2  shar4_2  attr2_2  sinc2_2  intel2_2  fun2_2  amb2_2  \\\n",
       "0     NaN     NaN      NaN      NaN      NaN       NaN     NaN     NaN   \n",
       "1     NaN     NaN      NaN      NaN      NaN       NaN     NaN     NaN   \n",
       "2     NaN     NaN      NaN      NaN      NaN       NaN     NaN     NaN   \n",
       "3     NaN     NaN      NaN      NaN      NaN       NaN     NaN     NaN   \n",
       "4     NaN     NaN      NaN      NaN      NaN       NaN     NaN     NaN   \n",
       "\n",
       "   shar2_2  attr3_2  sinc3_2  intel3_2  fun3_2  amb3_2  attr5_2  sinc5_2  \\\n",
       "0      NaN      6.0      7.0       8.0     7.0     6.0      NaN      NaN   \n",
       "1      NaN      6.0      7.0       8.0     7.0     6.0      NaN      NaN   \n",
       "2      NaN      6.0      7.0       8.0     7.0     6.0      NaN      NaN   \n",
       "3      NaN      6.0      7.0       8.0     7.0     6.0      NaN      NaN   \n",
       "4      NaN      6.0      7.0       8.0     7.0     6.0      NaN      NaN   \n",
       "\n",
       "   intel5_2  fun5_2  amb5_2  you_call  them_cal  date_3  numdat_3  num_in_3  \\\n",
       "0       NaN     NaN     NaN       1.0       1.0     0.0       NaN       NaN   \n",
       "1       NaN     NaN     NaN       1.0       1.0     0.0       NaN       NaN   \n",
       "2       NaN     NaN     NaN       1.0       1.0     0.0       NaN       NaN   \n",
       "3       NaN     NaN     NaN       1.0       1.0     0.0       NaN       NaN   \n",
       "4       NaN     NaN     NaN       1.0       1.0     0.0       NaN       NaN   \n",
       "\n",
       "   attr1_3  sinc1_3  intel1_3  fun1_3  amb1_3  shar1_3  attr7_3  sinc7_3  \\\n",
       "0     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "1     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "2     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "3     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "4     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "\n",
       "   intel7_3  fun7_3  amb7_3  shar7_3  attr4_3  sinc4_3  intel4_3  fun4_3  \\\n",
       "0       NaN     NaN     NaN      NaN      NaN      NaN       NaN     NaN   \n",
       "1       NaN     NaN     NaN      NaN      NaN      NaN       NaN     NaN   \n",
       "2       NaN     NaN     NaN      NaN      NaN      NaN       NaN     NaN   \n",
       "3       NaN     NaN     NaN      NaN      NaN      NaN       NaN     NaN   \n",
       "4       NaN     NaN     NaN      NaN      NaN      NaN       NaN     NaN   \n",
       "\n",
       "   amb4_3  shar4_3  attr2_3  sinc2_3  intel2_3  fun2_3  amb2_3  shar2_3  \\\n",
       "0     NaN      NaN      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "1     NaN      NaN      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "2     NaN      NaN      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "3     NaN      NaN      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "4     NaN      NaN      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "\n",
       "   attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
       "0      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "1      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "2      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "3      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "4      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "\n",
       "   fun5_3  amb5_3  \n",
       "0     NaN     NaN  \n",
       "1     NaN     NaN  \n",
       "2     NaN     NaN  \n",
       "3     NaN     NaN  \n",
       "4     NaN     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file, encoding= 'ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad0aea",
   "metadata": {},
   "source": [
    "#### 1. Basic checking of data\n",
    "\n",
    "Generally, don't tend to care about data types until we get an error or some unexpected results. However, it's better to check that data types are correctly loaded before you start your analysis. You can read more about data types in pandas [here](https://pbpython.com/pandas_dtypes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58391e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8378"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race_o</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>pf_o_fun</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>pf_o_sha</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>like_o</th>\n",
       "      <th>prob_o</th>\n",
       "      <th>met_o</th>\n",
       "      <th>age</th>\n",
       "      <th>field</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>undergra</th>\n",
       "      <th>mn_sat</th>\n",
       "      <th>tuition</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>from</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>income</th>\n",
       "      <th>goal</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>career</th>\n",
       "      <th>career_c</th>\n",
       "      <th>sports</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>expnum</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr4_1</th>\n",
       "      <th>sinc4_1</th>\n",
       "      <th>intel4_1</th>\n",
       "      <th>fun4_1</th>\n",
       "      <th>amb4_1</th>\n",
       "      <th>shar4_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>attr5_1</th>\n",
       "      <th>sinc5_1</th>\n",
       "      <th>intel5_1</th>\n",
       "      <th>fun5_1</th>\n",
       "      <th>amb5_1</th>\n",
       "      <th>dec</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "      <th>match_es</th>\n",
       "      <th>attr1_s</th>\n",
       "      <th>sinc1_s</th>\n",
       "      <th>intel1_s</th>\n",
       "      <th>fun1_s</th>\n",
       "      <th>amb1_s</th>\n",
       "      <th>shar1_s</th>\n",
       "      <th>attr3_s</th>\n",
       "      <th>sinc3_s</th>\n",
       "      <th>intel3_s</th>\n",
       "      <th>fun3_s</th>\n",
       "      <th>amb3_s</th>\n",
       "      <th>satis_2</th>\n",
       "      <th>length</th>\n",
       "      <th>numdat_2</th>\n",
       "      <th>attr7_2</th>\n",
       "      <th>sinc7_2</th>\n",
       "      <th>intel7_2</th>\n",
       "      <th>fun7_2</th>\n",
       "      <th>amb7_2</th>\n",
       "      <th>shar7_2</th>\n",
       "      <th>attr1_2</th>\n",
       "      <th>sinc1_2</th>\n",
       "      <th>intel1_2</th>\n",
       "      <th>fun1_2</th>\n",
       "      <th>amb1_2</th>\n",
       "      <th>shar1_2</th>\n",
       "      <th>attr4_2</th>\n",
       "      <th>sinc4_2</th>\n",
       "      <th>intel4_2</th>\n",
       "      <th>fun4_2</th>\n",
       "      <th>amb4_2</th>\n",
       "      <th>shar4_2</th>\n",
       "      <th>attr2_2</th>\n",
       "      <th>sinc2_2</th>\n",
       "      <th>intel2_2</th>\n",
       "      <th>fun2_2</th>\n",
       "      <th>amb2_2</th>\n",
       "      <th>shar2_2</th>\n",
       "      <th>attr3_2</th>\n",
       "      <th>sinc3_2</th>\n",
       "      <th>intel3_2</th>\n",
       "      <th>fun3_2</th>\n",
       "      <th>amb3_2</th>\n",
       "      <th>attr5_2</th>\n",
       "      <th>sinc5_2</th>\n",
       "      <th>intel5_2</th>\n",
       "      <th>fun5_2</th>\n",
       "      <th>amb5_2</th>\n",
       "      <th>you_call</th>\n",
       "      <th>them_cal</th>\n",
       "      <th>date_3</th>\n",
       "      <th>numdat_3</th>\n",
       "      <th>num_in_3</th>\n",
       "      <th>attr1_3</th>\n",
       "      <th>sinc1_3</th>\n",
       "      <th>intel1_3</th>\n",
       "      <th>fun1_3</th>\n",
       "      <th>amb1_3</th>\n",
       "      <th>shar1_3</th>\n",
       "      <th>attr7_3</th>\n",
       "      <th>sinc7_3</th>\n",
       "      <th>intel7_3</th>\n",
       "      <th>fun7_3</th>\n",
       "      <th>amb7_3</th>\n",
       "      <th>shar7_3</th>\n",
       "      <th>attr4_3</th>\n",
       "      <th>sinc4_3</th>\n",
       "      <th>intel4_3</th>\n",
       "      <th>fun4_3</th>\n",
       "      <th>amb4_3</th>\n",
       "      <th>shar4_3</th>\n",
       "      <th>attr2_3</th>\n",
       "      <th>sinc2_3</th>\n",
       "      <th>intel2_3</th>\n",
       "      <th>fun2_3</th>\n",
       "      <th>amb2_3</th>\n",
       "      <th>shar2_3</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data types</th>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              iid       id gender    idg condtn   wave  round position  \\\n",
       "data types  int64  float64  int64  int64  int64  int64  int64    int64   \n",
       "\n",
       "           positin1  order partner      pid  match int_corr samerace    age_o  \\\n",
       "data types  float64  int64   int64  float64  int64  float64    int64  float64   \n",
       "\n",
       "             race_o pf_o_att pf_o_sin pf_o_int pf_o_fun pf_o_amb pf_o_sha  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "            dec_o   attr_o   sinc_o  intel_o    fun_o    amb_o   shar_o  \\\n",
       "data types  int64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "             like_o   prob_o    met_o      age   field field_cd undergra  \\\n",
       "data types  float64  float64  float64  float64  object  float64   object   \n",
       "\n",
       "            mn_sat tuition     race  imprace imprelig    from zipcode  income  \\\n",
       "data types  object  object  float64  float64  float64  object  object  object   \n",
       "\n",
       "               goal     date   go_out  career career_c   sports tvsports  \\\n",
       "data types  float64  float64  float64  object  float64  float64  float64   \n",
       "\n",
       "           exercise   dining  museums      art   hiking   gaming clubbing  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "            reading       tv  theater   movies concerts    music shopping  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "               yoga exphappy   expnum  attr1_1  sinc1_1 intel1_1   fun1_1  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "             amb1_1  shar1_1  attr4_1  sinc4_1 intel4_1   fun4_1   amb4_1  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "            shar4_1  attr2_1  sinc2_1 intel2_1   fun2_1   amb2_1  shar2_1  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "            attr3_1  sinc3_1   fun3_1 intel3_1   amb3_1  attr5_1  sinc5_1  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "           intel5_1   fun5_1   amb5_1    dec     attr     sinc    intel  \\\n",
       "data types  float64  float64  float64  int64  float64  float64  float64   \n",
       "\n",
       "                fun      amb     shar     like     prob      met match_es  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "            attr1_s  sinc1_s intel1_s   fun1_s   amb1_s  shar1_s  attr3_s  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "            sinc3_s intel3_s   fun3_s   amb3_s  satis_2   length numdat_2  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "            attr7_2  sinc7_2 intel7_2   fun7_2   amb7_2  shar7_2  attr1_2  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "            sinc1_2 intel1_2   fun1_2   amb1_2  shar1_2  attr4_2  sinc4_2  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "           intel4_2   fun4_2   amb4_2  shar4_2  attr2_2  sinc2_2 intel2_2  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "             fun2_2   amb2_2  shar2_2  attr3_2  sinc3_2 intel3_2   fun3_2  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "             amb3_2  attr5_2  sinc5_2 intel5_2   fun5_2   amb5_2 you_call  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "           them_cal   date_3 numdat_3 num_in_3  attr1_3  sinc1_3 intel1_3  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "             fun1_3   amb1_3  shar1_3  attr7_3  sinc7_3 intel7_3   fun7_3  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "             amb7_3  shar7_3  attr4_3  sinc4_3 intel4_3   fun4_3   amb4_3  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "            shar4_3  attr2_3  sinc2_3 intel2_3   fun2_3   amb2_3  shar2_3  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "            attr3_3  sinc3_3 intel3_3   fun3_3   amb3_3  attr5_3  sinc5_3  \\\n",
       "data types  float64  float64  float64  float64  float64  float64  float64   \n",
       "\n",
       "           intel5_3   fun5_3   amb5_3  \n",
       "data types  float64  float64  float64  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n",
    "len(df.columns)\n",
    "df.dtypes.to_frame(name='data types').T # T will represent the transpose of the resulting dataframe, better for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c1276",
   "metadata": {},
   "source": [
    "##### Comment\n",
    "- Seems like all the features were loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd252c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Categorical Features'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <td>8315</td>\n",
       "      <td>259</td>\n",
       "      <td>Business</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undergra</th>\n",
       "      <td>4914</td>\n",
       "      <td>241</td>\n",
       "      <td>UC Berkeley</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mn_sat</th>\n",
       "      <td>3133</td>\n",
       "      <td>68</td>\n",
       "      <td>1,400.00</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuition</th>\n",
       "      <td>3583</td>\n",
       "      <td>115</td>\n",
       "      <td>26,908.00</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>8299</td>\n",
       "      <td>269</td>\n",
       "      <td>New York</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>7314</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>4279</td>\n",
       "      <td>261</td>\n",
       "      <td>55,080.00</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>8289</td>\n",
       "      <td>367</td>\n",
       "      <td>Finance</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count unique          top freq\n",
       "field     8315    259     Business  521\n",
       "undergra  4914    241  UC Berkeley  107\n",
       "mn_sat    3133     68     1,400.00  403\n",
       "tuition   3583    115    26,908.00  241\n",
       "from      8299    269     New York  522\n",
       "zipcode   7314    409            0  355\n",
       "income    4279    261    55,080.00  124\n",
       "career    8289    367      Finance  202"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(\"Categorical Features\")\n",
    "df.describe(include='O').T \n",
    "\n",
    "#display(\"Numeric Features\")\n",
    "#df.describe(include='number').T "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3cf6c",
   "metadata": {},
   "source": [
    "Some features have wrong data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9791cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_str_to_int = ['mn_sat', 'tuition', 'zipcode', 'income'] # features which needs to be converted to int\n",
    "for col in cols_str_to_int:\n",
    "    df[col] = df[col].fillna('0').str.replace(\",\",\"\").astype(np.float).astype(int)\n",
    "    # df[col] = pd.to_numeric(df[col].str.replace(\",\",\"\"), errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36c97aa",
   "metadata": {},
   "source": [
    "Verify that data type is changed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f249b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Categorical Features'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <td>8315</td>\n",
       "      <td>259</td>\n",
       "      <td>Business</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undergra</th>\n",
       "      <td>4914</td>\n",
       "      <td>241</td>\n",
       "      <td>UC Berkeley</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>8299</td>\n",
       "      <td>269</td>\n",
       "      <td>New York</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>8289</td>\n",
       "      <td>367</td>\n",
       "      <td>Finance</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count unique          top freq\n",
       "field     8315    259     Business  521\n",
       "undergra  4914    241  UC Berkeley  107\n",
       "from      8299    269     New York  522\n",
       "career    8289    367      Finance  202"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(\"Categorical Features\")\n",
    "df.describe(include='O').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f108efcf",
   "metadata": {},
   "source": [
    "#### 2. Columns renaming\n",
    "\n",
    "It's better to rename columns (without white characters and preferably in _lower case_), so it's easier to deal with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f304651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>iid</td>\n",
       "      <td>id</td>\n",
       "      <td>gender</td>\n",
       "      <td>idg</td>\n",
       "      <td>condtn</td>\n",
       "      <td>wave</td>\n",
       "      <td>round</td>\n",
       "      <td>position</td>\n",
       "      <td>positin1</td>\n",
       "      <td>order</td>\n",
       "      <td>partner</td>\n",
       "      <td>pid</td>\n",
       "      <td>match</td>\n",
       "      <td>int_corr</td>\n",
       "      <td>samerace</td>\n",
       "      <td>age_o</td>\n",
       "      <td>race_o</td>\n",
       "      <td>pf_o_att</td>\n",
       "      <td>pf_o_sin</td>\n",
       "      <td>pf_o_int</td>\n",
       "      <td>pf_o_fun</td>\n",
       "      <td>pf_o_amb</td>\n",
       "      <td>pf_o_sha</td>\n",
       "      <td>dec_o</td>\n",
       "      <td>attr_o</td>\n",
       "      <td>sinc_o</td>\n",
       "      <td>intel_o</td>\n",
       "      <td>fun_o</td>\n",
       "      <td>amb_o</td>\n",
       "      <td>shar_o</td>\n",
       "      <td>like_o</td>\n",
       "      <td>prob_o</td>\n",
       "      <td>met_o</td>\n",
       "      <td>age</td>\n",
       "      <td>field</td>\n",
       "      <td>field_cd</td>\n",
       "      <td>undergra</td>\n",
       "      <td>mn_sat</td>\n",
       "      <td>tuition</td>\n",
       "      <td>race</td>\n",
       "      <td>imprace</td>\n",
       "      <td>imprelig</td>\n",
       "      <td>from</td>\n",
       "      <td>zipcode</td>\n",
       "      <td>income</td>\n",
       "      <td>goal</td>\n",
       "      <td>date</td>\n",
       "      <td>go_out</td>\n",
       "      <td>career</td>\n",
       "      <td>career_c</td>\n",
       "      <td>sports</td>\n",
       "      <td>tvsports</td>\n",
       "      <td>exercise</td>\n",
       "      <td>dining</td>\n",
       "      <td>museums</td>\n",
       "      <td>art</td>\n",
       "      <td>hiking</td>\n",
       "      <td>gaming</td>\n",
       "      <td>clubbing</td>\n",
       "      <td>reading</td>\n",
       "      <td>tv</td>\n",
       "      <td>theater</td>\n",
       "      <td>movies</td>\n",
       "      <td>concerts</td>\n",
       "      <td>music</td>\n",
       "      <td>shopping</td>\n",
       "      <td>yoga</td>\n",
       "      <td>exphappy</td>\n",
       "      <td>expnum</td>\n",
       "      <td>attr1_1</td>\n",
       "      <td>sinc1_1</td>\n",
       "      <td>intel1_1</td>\n",
       "      <td>fun1_1</td>\n",
       "      <td>amb1_1</td>\n",
       "      <td>shar1_1</td>\n",
       "      <td>attr4_1</td>\n",
       "      <td>sinc4_1</td>\n",
       "      <td>intel4_1</td>\n",
       "      <td>fun4_1</td>\n",
       "      <td>amb4_1</td>\n",
       "      <td>shar4_1</td>\n",
       "      <td>attr2_1</td>\n",
       "      <td>sinc2_1</td>\n",
       "      <td>intel2_1</td>\n",
       "      <td>fun2_1</td>\n",
       "      <td>amb2_1</td>\n",
       "      <td>shar2_1</td>\n",
       "      <td>attr3_1</td>\n",
       "      <td>sinc3_1</td>\n",
       "      <td>fun3_1</td>\n",
       "      <td>intel3_1</td>\n",
       "      <td>amb3_1</td>\n",
       "      <td>attr5_1</td>\n",
       "      <td>sinc5_1</td>\n",
       "      <td>intel5_1</td>\n",
       "      <td>fun5_1</td>\n",
       "      <td>amb5_1</td>\n",
       "      <td>dec</td>\n",
       "      <td>attr</td>\n",
       "      <td>sinc</td>\n",
       "      <td>intel</td>\n",
       "      <td>fun</td>\n",
       "      <td>amb</td>\n",
       "      <td>shar</td>\n",
       "      <td>like</td>\n",
       "      <td>prob</td>\n",
       "      <td>met</td>\n",
       "      <td>match_es</td>\n",
       "      <td>attr1_s</td>\n",
       "      <td>sinc1_s</td>\n",
       "      <td>intel1_s</td>\n",
       "      <td>fun1_s</td>\n",
       "      <td>amb1_s</td>\n",
       "      <td>shar1_s</td>\n",
       "      <td>attr3_s</td>\n",
       "      <td>sinc3_s</td>\n",
       "      <td>intel3_s</td>\n",
       "      <td>fun3_s</td>\n",
       "      <td>amb3_s</td>\n",
       "      <td>satis_2</td>\n",
       "      <td>length</td>\n",
       "      <td>numdat_2</td>\n",
       "      <td>attr7_2</td>\n",
       "      <td>sinc7_2</td>\n",
       "      <td>intel7_2</td>\n",
       "      <td>fun7_2</td>\n",
       "      <td>amb7_2</td>\n",
       "      <td>shar7_2</td>\n",
       "      <td>attr1_2</td>\n",
       "      <td>sinc1_2</td>\n",
       "      <td>intel1_2</td>\n",
       "      <td>fun1_2</td>\n",
       "      <td>amb1_2</td>\n",
       "      <td>shar1_2</td>\n",
       "      <td>attr4_2</td>\n",
       "      <td>sinc4_2</td>\n",
       "      <td>intel4_2</td>\n",
       "      <td>fun4_2</td>\n",
       "      <td>amb4_2</td>\n",
       "      <td>shar4_2</td>\n",
       "      <td>attr2_2</td>\n",
       "      <td>sinc2_2</td>\n",
       "      <td>intel2_2</td>\n",
       "      <td>fun2_2</td>\n",
       "      <td>amb2_2</td>\n",
       "      <td>shar2_2</td>\n",
       "      <td>attr3_2</td>\n",
       "      <td>sinc3_2</td>\n",
       "      <td>intel3_2</td>\n",
       "      <td>fun3_2</td>\n",
       "      <td>amb3_2</td>\n",
       "      <td>attr5_2</td>\n",
       "      <td>sinc5_2</td>\n",
       "      <td>intel5_2</td>\n",
       "      <td>fun5_2</td>\n",
       "      <td>amb5_2</td>\n",
       "      <td>you_call</td>\n",
       "      <td>them_cal</td>\n",
       "      <td>date_3</td>\n",
       "      <td>numdat_3</td>\n",
       "      <td>num_in_3</td>\n",
       "      <td>attr1_3</td>\n",
       "      <td>sinc1_3</td>\n",
       "      <td>intel1_3</td>\n",
       "      <td>fun1_3</td>\n",
       "      <td>amb1_3</td>\n",
       "      <td>shar1_3</td>\n",
       "      <td>attr7_3</td>\n",
       "      <td>sinc7_3</td>\n",
       "      <td>intel7_3</td>\n",
       "      <td>fun7_3</td>\n",
       "      <td>amb7_3</td>\n",
       "      <td>shar7_3</td>\n",
       "      <td>attr4_3</td>\n",
       "      <td>sinc4_3</td>\n",
       "      <td>intel4_3</td>\n",
       "      <td>fun4_3</td>\n",
       "      <td>amb4_3</td>\n",
       "      <td>shar4_3</td>\n",
       "      <td>attr2_3</td>\n",
       "      <td>sinc2_3</td>\n",
       "      <td>intel2_3</td>\n",
       "      <td>fun2_3</td>\n",
       "      <td>amb2_3</td>\n",
       "      <td>shar2_3</td>\n",
       "      <td>attr3_3</td>\n",
       "      <td>sinc3_3</td>\n",
       "      <td>intel3_3</td>\n",
       "      <td>fun3_3</td>\n",
       "      <td>amb3_3</td>\n",
       "      <td>attr5_3</td>\n",
       "      <td>sinc5_3</td>\n",
       "      <td>intel5_3</td>\n",
       "      <td>fun5_3</td>\n",
       "      <td>amb5_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1       2    3       4     5      6         7         8      9    \\\n",
       "index  iid  id  gender  idg  condtn  wave  round  position  positin1  order   \n",
       "\n",
       "           10   11     12        13        14     15      16        17   \\\n",
       "index  partner  pid  match  int_corr  samerace  age_o  race_o  pf_o_att   \n",
       "\n",
       "            18        19        20        21        22     23      24   \\\n",
       "index  pf_o_sin  pf_o_int  pf_o_fun  pf_o_amb  pf_o_sha  dec_o  attr_o   \n",
       "\n",
       "          25       26     27     28      29      30      31     32   33   \\\n",
       "index  sinc_o  intel_o  fun_o  amb_o  shar_o  like_o  prob_o  met_o  age   \n",
       "\n",
       "         34        35        36      37       38    39       40        41   \\\n",
       "index  field  field_cd  undergra  mn_sat  tuition  race  imprace  imprelig   \n",
       "\n",
       "        42       43      44    45    46      47      48        49      50   \\\n",
       "index  from  zipcode  income  goal  date  go_out  career  career_c  sports   \n",
       "\n",
       "            51        52      53       54   55      56      57        58   \\\n",
       "index  tvsports  exercise  dining  museums  art  hiking  gaming  clubbing   \n",
       "\n",
       "           59  60       61      62        63     64        65    66   \\\n",
       "index  reading  tv  theater  movies  concerts  music  shopping  yoga   \n",
       "\n",
       "            67      68       69       70        71      72      73       74   \\\n",
       "index  exphappy  expnum  attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1   \n",
       "\n",
       "           75       76        77      78      79       80       81       82   \\\n",
       "index  attr4_1  sinc4_1  intel4_1  fun4_1  amb4_1  shar4_1  attr2_1  sinc2_1   \n",
       "\n",
       "            83      84      85       86       87       88      89        90   \\\n",
       "index  intel2_1  fun2_1  amb2_1  shar2_1  attr3_1  sinc3_1  fun3_1  intel3_1   \n",
       "\n",
       "          91       92       93        94      95      96   97    98    99   \\\n",
       "index  amb3_1  attr5_1  sinc5_1  intel5_1  fun5_1  amb5_1  dec  attr  sinc   \n",
       "\n",
       "         100  101  102   103   104   105  106       107      108      109  \\\n",
       "index  intel  fun  amb  shar  like  prob  met  match_es  attr1_s  sinc1_s   \n",
       "\n",
       "            110     111     112      113      114      115       116     117  \\\n",
       "index  intel1_s  fun1_s  amb1_s  shar1_s  attr3_s  sinc3_s  intel3_s  fun3_s   \n",
       "\n",
       "          118      119     120       121      122      123       124     125  \\\n",
       "index  amb3_s  satis_2  length  numdat_2  attr7_2  sinc7_2  intel7_2  fun7_2   \n",
       "\n",
       "          126      127      128      129       130     131     132      133  \\\n",
       "index  amb7_2  shar7_2  attr1_2  sinc1_2  intel1_2  fun1_2  amb1_2  shar1_2   \n",
       "\n",
       "           134      135       136     137     138      139      140      141  \\\n",
       "index  attr4_2  sinc4_2  intel4_2  fun4_2  amb4_2  shar4_2  attr2_2  sinc2_2   \n",
       "\n",
       "            142     143     144      145      146      147       148     149  \\\n",
       "index  intel2_2  fun2_2  amb2_2  shar2_2  attr3_2  sinc3_2  intel3_2  fun3_2   \n",
       "\n",
       "          150      151      152       153     154     155       156       157  \\\n",
       "index  amb3_2  attr5_2  sinc5_2  intel5_2  fun5_2  amb5_2  you_call  them_cal   \n",
       "\n",
       "          158       159       160      161      162       163     164     165  \\\n",
       "index  date_3  numdat_3  num_in_3  attr1_3  sinc1_3  intel1_3  fun1_3  amb1_3   \n",
       "\n",
       "           166      167      168       169     170     171      172      173  \\\n",
       "index  shar1_3  attr7_3  sinc7_3  intel7_3  fun7_3  amb7_3  shar7_3  attr4_3   \n",
       "\n",
       "           174       175     176     177      178      179      180       181  \\\n",
       "index  sinc4_3  intel4_3  fun4_3  amb4_3  shar4_3  attr2_3  sinc2_3  intel2_3   \n",
       "\n",
       "          182     183      184      185      186       187     188     189  \\\n",
       "index  fun2_3  amb2_3  shar2_3  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3   \n",
       "\n",
       "           190      191       192     193     194  \n",
       "index  attr5_3  sinc5_3  intel5_3  fun5_3  amb5_3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_frame().reset_index().T.head(1) # showing columns in a more visual way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13b45e",
   "metadata": {},
   "source": [
    "##### Comment\n",
    "\n",
    "- No need to change the column names since all are lower case and without any white characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bba4bd",
   "metadata": {},
   "source": [
    "#### 3. Split your dataset into train and test datasets\n",
    "\n",
    "We will split our dataset into two parts: `train` & `test` datasets. We will do all the processing on the `train` dataset. `test` dataset will remain unknown to us. And we will use it only for testing analysis. This is to simulate the real world scenario in which we don't know the data which would be run on our model (after deploying)\n",
    "\n",
    "However, there may be some issues with the `test` dataset (especially if our original dataset is bit imbalance):\n",
    "\n",
    "1. What if few categories are missed in `test` dataset ? we won't have any hot encoding for those categories.\n",
    "\n",
    "> One possible solution is to hot encode the new unseen categories as zero (or some default category)\n",
    "\n",
    "> Another possible solution is to do stratified sampling (in case of imbalance data), so you have data for all the categories in both `train` and `test` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a95d043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df.dec.replace(0, 'No').replace(1, 'Yes').value_counts().plot(kind = 'bar')\n",
    "count_ss = df.dec.replace(0, 'No').replace(1, 'Yes').value_counts() # final decision. 1 = Yes, 0 = No\n",
    "ax = sns.barplot(x = count_ss.index, y = count_ss.values)\n",
    "_ = ax.set(xlabel='decision', ylabel='count')\n",
    "_ = ax.bar_label(ax.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbceec",
   "metadata": {},
   "source": [
    "We have a sightly imbalance data (for `decision` parameter). We will be doing a stratified split for equal proprtion in `train` and `test` datasets. You can check the official doc for `train_test_split` [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0567809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the random state too, so you we can reproduce the results later as well\n",
    "__random_state = 0\n",
    "\n",
    "# let's do a 85% | 15% split\n",
    "train_df, test_df = train_test_split(df, test_size=0.15, shuffle=True, random_state=__random_state, stratify=df['dec'])\n",
    "\n",
    "# reset the index for train and test\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f59eec21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = train_df.dec.replace(0, 'No').replace(1, 'Yes').value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f5e46a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = test_df.dec.replace(0, 'No').replace(1, 'Yes').value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66430aec",
   "metadata": {},
   "source": [
    "Both `train` and `test` datasets have the same ratio of values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03b69f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.describe(include='all').T # check train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcfcc29",
   "metadata": {},
   "source": [
    "Save the `test` dataset as a `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa848134",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = join(data_dir, \"test.csv\")\n",
    "dataframe_to_csv(test_df, test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd778c23",
   "metadata": {},
   "source": [
    "#### 4. Check for missing data\n",
    "\n",
    "We need to check for missing data and imputate or remove it. It is really important to deal with all the missing data to get better EDA and less incorrect results during model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b9dd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a basic first step is to check if any data is missing in predicted value\n",
    "# because if some labels are not there in y_train, there isn't any point to include those rows\n",
    "\n",
    "train_df['dec'].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2df2a",
   "metadata": {},
   "source": [
    "So basically we are good here. Now let's see how much missing values we have for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29c0d02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_in_3</th>\n",
       "      <th>numdat_3</th>\n",
       "      <th>expnum</th>\n",
       "      <th>sinc7_2</th>\n",
       "      <th>amb7_2</th>\n",
       "      <th>shar7_2</th>\n",
       "      <th>attr7_2</th>\n",
       "      <th>intel7_2</th>\n",
       "      <th>fun7_2</th>\n",
       "      <th>amb5_3</th>\n",
       "      <th>intel7_3</th>\n",
       "      <th>attr7_3</th>\n",
       "      <th>shar2_3</th>\n",
       "      <th>sinc7_3</th>\n",
       "      <th>fun7_3</th>\n",
       "      <th>amb7_3</th>\n",
       "      <th>shar7_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>fun2_3</th>\n",
       "      <th>attr4_3</th>\n",
       "      <th>sinc4_3</th>\n",
       "      <th>intel4_3</th>\n",
       "      <th>fun4_3</th>\n",
       "      <th>shar4_3</th>\n",
       "      <th>attr2_3</th>\n",
       "      <th>sinc2_3</th>\n",
       "      <th>intel2_3</th>\n",
       "      <th>amb4_3</th>\n",
       "      <th>amb2_3</th>\n",
       "      <th>them_cal</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>fun1_3</th>\n",
       "      <th>amb1_3</th>\n",
       "      <th>attr1_3</th>\n",
       "      <th>date_3</th>\n",
       "      <th>shar1_3</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>sinc1_3</th>\n",
       "      <th>you_call</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>intel1_3</th>\n",
       "      <th>amb3_s</th>\n",
       "      <th>fun3_s</th>\n",
       "      <th>intel3_s</th>\n",
       "      <th>sinc3_s</th>\n",
       "      <th>attr3_s</th>\n",
       "      <th>fun1_s</th>\n",
       "      <th>intel1_s</th>\n",
       "      <th>amb1_s</th>\n",
       "      <th>sinc1_s</th>\n",
       "      <th>attr1_s</th>\n",
       "      <th>shar1_s</th>\n",
       "      <th>sinc5_2</th>\n",
       "      <th>attr5_2</th>\n",
       "      <th>intel5_2</th>\n",
       "      <th>fun5_2</th>\n",
       "      <th>amb5_2</th>\n",
       "      <th>amb5_1</th>\n",
       "      <th>fun5_1</th>\n",
       "      <th>intel5_1</th>\n",
       "      <th>sinc5_1</th>\n",
       "      <th>attr5_1</th>\n",
       "      <th>undergra</th>\n",
       "      <th>attr4_2</th>\n",
       "      <th>fun4_2</th>\n",
       "      <th>intel4_2</th>\n",
       "      <th>sinc4_2</th>\n",
       "      <th>amb4_2</th>\n",
       "      <th>sinc2_2</th>\n",
       "      <th>shar2_2</th>\n",
       "      <th>shar4_2</th>\n",
       "      <th>fun2_2</th>\n",
       "      <th>intel2_2</th>\n",
       "      <th>amb2_2</th>\n",
       "      <th>attr2_2</th>\n",
       "      <th>shar4_1</th>\n",
       "      <th>fun4_1</th>\n",
       "      <th>attr4_1</th>\n",
       "      <th>sinc4_1</th>\n",
       "      <th>intel4_1</th>\n",
       "      <th>amb4_1</th>\n",
       "      <th>positin1</th>\n",
       "      <th>match_es</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>shar</th>\n",
       "      <th>numdat_2</th>\n",
       "      <th>attr1_2</th>\n",
       "      <th>satis_2</th>\n",
       "      <th>intel3_2</th>\n",
       "      <th>fun3_2</th>\n",
       "      <th>amb3_2</th>\n",
       "      <th>sinc3_2</th>\n",
       "      <th>attr3_2</th>\n",
       "      <th>length</th>\n",
       "      <th>shar1_2</th>\n",
       "      <th>amb1_2</th>\n",
       "      <th>fun1_2</th>\n",
       "      <th>intel1_2</th>\n",
       "      <th>sinc1_2</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>amb</th>\n",
       "      <th>met</th>\n",
       "      <th>met_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>fun</th>\n",
       "      <th>prob_o</th>\n",
       "      <th>prob</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>intel</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>sinc</th>\n",
       "      <th>like_o</th>\n",
       "      <th>like</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>attr</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>career_c</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>pf_o_sha</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>career</th>\n",
       "      <th>pf_o_fun</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>from</th>\n",
       "      <th>museums</th>\n",
       "      <th>goal</th>\n",
       "      <th>imprace</th>\n",
       "      <th>go_out</th>\n",
       "      <th>sports</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>yoga</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>gaming</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>shopping</th>\n",
       "      <th>music</th>\n",
       "      <th>concerts</th>\n",
       "      <th>movies</th>\n",
       "      <th>theater</th>\n",
       "      <th>reading</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>tv</th>\n",
       "      <th>race_o</th>\n",
       "      <th>race</th>\n",
       "      <th>field</th>\n",
       "      <th>pid</th>\n",
       "      <th>id</th>\n",
       "      <th>iid</th>\n",
       "      <th>income</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>tuition</th>\n",
       "      <th>mn_sat</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>match</th>\n",
       "      <th>partner</th>\n",
       "      <th>order</th>\n",
       "      <th>position</th>\n",
       "      <th>round</th>\n",
       "      <th>wave</th>\n",
       "      <th>condtn</th>\n",
       "      <th>idg</th>\n",
       "      <th>gender</th>\n",
       "      <th>dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missing %</th>\n",
       "      <td>92.037635</td>\n",
       "      <td>82.207555</td>\n",
       "      <td>78.654683</td>\n",
       "      <td>76.576324</td>\n",
       "      <td>76.576324</td>\n",
       "      <td>76.393765</td>\n",
       "      <td>76.267378</td>\n",
       "      <td>76.267378</td>\n",
       "      <td>76.267378</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>76.070777</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>64.850442</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>52.773487</td>\n",
       "      <td>51.973037</td>\n",
       "      <td>51.973037</td>\n",
       "      <td>51.973037</td>\n",
       "      <td>51.973037</td>\n",
       "      <td>51.973037</td>\n",
       "      <td>50.765342</td>\n",
       "      <td>50.765342</td>\n",
       "      <td>50.765342</td>\n",
       "      <td>50.765342</td>\n",
       "      <td>50.765342</td>\n",
       "      <td>50.765342</td>\n",
       "      <td>47.746103</td>\n",
       "      <td>47.746103</td>\n",
       "      <td>47.746103</td>\n",
       "      <td>47.746103</td>\n",
       "      <td>47.746103</td>\n",
       "      <td>41.468895</td>\n",
       "      <td>41.468895</td>\n",
       "      <td>41.468895</td>\n",
       "      <td>41.468895</td>\n",
       "      <td>41.468895</td>\n",
       "      <td>41.426766</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>30.866451</td>\n",
       "      <td>22.7777</td>\n",
       "      <td>22.482797</td>\n",
       "      <td>22.482797</td>\n",
       "      <td>22.482797</td>\n",
       "      <td>22.482797</td>\n",
       "      <td>22.482797</td>\n",
       "      <td>21.949164</td>\n",
       "      <td>13.888499</td>\n",
       "      <td>12.821233</td>\n",
       "      <td>12.736975</td>\n",
       "      <td>11.276506</td>\n",
       "      <td>11.065862</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>10.883303</td>\n",
       "      <td>8.636427</td>\n",
       "      <td>8.580256</td>\n",
       "      <td>4.578009</td>\n",
       "      <td>4.563966</td>\n",
       "      <td>4.297149</td>\n",
       "      <td>4.142677</td>\n",
       "      <td>3.833731</td>\n",
       "      <td>3.777559</td>\n",
       "      <td>3.777559</td>\n",
       "      <td>3.651173</td>\n",
       "      <td>3.468614</td>\n",
       "      <td>3.440528</td>\n",
       "      <td>3.033282</td>\n",
       "      <td>2.906895</td>\n",
       "      <td>2.640079</td>\n",
       "      <td>2.485606</td>\n",
       "      <td>1.881758</td>\n",
       "      <td>1.755371</td>\n",
       "      <td>1.55877</td>\n",
       "      <td>1.474512</td>\n",
       "      <td>1.263867</td>\n",
       "      <td>1.263867</td>\n",
       "      <td>1.249824</td>\n",
       "      <td>1.249824</td>\n",
       "      <td>1.249824</td>\n",
       "      <td>1.249824</td>\n",
       "      <td>1.249824</td>\n",
       "      <td>1.249824</td>\n",
       "      <td>1.221739</td>\n",
       "      <td>1.207696</td>\n",
       "      <td>1.193653</td>\n",
       "      <td>1.137481</td>\n",
       "      <td>1.137481</td>\n",
       "      <td>1.123438</td>\n",
       "      <td>1.123438</td>\n",
       "      <td>1.123438</td>\n",
       "      <td>1.053223</td>\n",
       "      <td>1.025137</td>\n",
       "      <td>1.025137</td>\n",
       "      <td>1.025137</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.800449</td>\n",
       "      <td>0.800449</td>\n",
       "      <td>0.800449</td>\n",
       "      <td>0.14043</td>\n",
       "      <td>0.014043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num_in_3   numdat_3     expnum    sinc7_2     amb7_2    shar7_2  \\\n",
       "missing %  92.037635  82.207555  78.654683  76.576324  76.576324  76.393765   \n",
       "\n",
       "             attr7_2   intel7_2     fun7_2     amb5_3   intel7_3    attr7_3  \\\n",
       "missing %  76.267378  76.267378  76.267378  76.070777  76.070777  76.070777   \n",
       "\n",
       "             shar2_3    sinc7_3     fun7_3     amb7_3    shar7_3    attr5_3  \\\n",
       "missing %  76.070777  76.070777  76.070777  76.070777  76.070777  76.070777   \n",
       "\n",
       "             sinc5_3   intel5_3     fun5_3     fun2_3    attr4_3    sinc4_3  \\\n",
       "missing %  76.070777  76.070777  76.070777  64.850442  64.850442  64.850442   \n",
       "\n",
       "            intel4_3     fun4_3    shar4_3    attr2_3    sinc2_3   intel2_3  \\\n",
       "missing %  64.850442  64.850442  64.850442  64.850442  64.850442  64.850442   \n",
       "\n",
       "              amb4_3     amb2_3   them_cal    sinc3_3     fun1_3     amb1_3  \\\n",
       "missing %  64.850442  64.850442  52.773487  52.773487  52.773487  52.773487   \n",
       "\n",
       "             attr1_3     date_3    shar1_3    attr3_3   intel3_3    sinc1_3  \\\n",
       "missing %  52.773487  52.773487  52.773487  52.773487  52.773487  52.773487   \n",
       "\n",
       "            you_call     fun3_3     amb3_3   intel1_3     amb3_s     fun3_s  \\\n",
       "missing %  52.773487  52.773487  52.773487  52.773487  51.973037  51.973037   \n",
       "\n",
       "            intel3_s    sinc3_s    attr3_s     fun1_s   intel1_s     amb1_s  \\\n",
       "missing %  51.973037  51.973037  51.973037  50.765342  50.765342  50.765342   \n",
       "\n",
       "             sinc1_s    attr1_s    shar1_s    sinc5_2    attr5_2   intel5_2  \\\n",
       "missing %  50.765342  50.765342  50.765342  47.746103  47.746103  47.746103   \n",
       "\n",
       "              fun5_2     amb5_2     amb5_1     fun5_1   intel5_1    sinc5_1  \\\n",
       "missing %  47.746103  47.746103  41.468895  41.468895  41.468895  41.468895   \n",
       "\n",
       "             attr5_1   undergra    attr4_2     fun4_2   intel4_2    sinc4_2  \\\n",
       "missing %  41.468895  41.426766  30.866451  30.866451  30.866451  30.866451   \n",
       "\n",
       "              amb4_2    sinc2_2    shar2_2    shar4_2     fun2_2   intel2_2  \\\n",
       "missing %  30.866451  30.866451  30.866451  30.866451  30.866451  30.866451   \n",
       "\n",
       "              amb2_2    attr2_2  shar4_1     fun4_1    attr4_1    sinc4_1  \\\n",
       "missing %  30.866451  30.866451  22.7777  22.482797  22.482797  22.482797   \n",
       "\n",
       "            intel4_1     amb4_1   positin1   match_es     shar_o       shar  \\\n",
       "missing %  22.482797  22.482797  21.949164  13.888499  12.821233  12.736975   \n",
       "\n",
       "            numdat_2    attr1_2    satis_2   intel3_2     fun3_2     amb3_2  \\\n",
       "missing %  11.276506  11.065862  10.883303  10.883303  10.883303  10.883303   \n",
       "\n",
       "             sinc3_2    attr3_2     length    shar1_2     amb1_2     fun1_2  \\\n",
       "missing %  10.883303  10.883303  10.883303  10.883303  10.883303  10.883303   \n",
       "\n",
       "            intel1_2    sinc1_2     amb_o       amb       met     met_o  \\\n",
       "missing %  10.883303  10.883303  8.636427  8.580256  4.578009  4.563966   \n",
       "\n",
       "              fun_o       fun    prob_o      prob   intel_o     intel  \\\n",
       "missing %  4.297149  4.142677  3.833731  3.777559  3.777559  3.651173   \n",
       "\n",
       "             sinc_o      sinc    like_o      like    attr_o      attr  \\\n",
       "missing %  3.468614  3.440528  3.033282  2.906895  2.640079  2.485606   \n",
       "\n",
       "           int_corr  career_c  shar1_1  pf_o_sha  exphappy    amb1_1  \\\n",
       "missing %  1.881758  1.755371  1.55877  1.474512  1.263867  1.263867   \n",
       "\n",
       "            attr3_1    fun3_1   sinc3_1    amb3_1  intel3_1  pf_o_amb  \\\n",
       "missing %  1.249824  1.249824  1.249824  1.249824  1.249824  1.249824   \n",
       "\n",
       "               date       age     age_o    career  pf_o_fun   shar2_1  \\\n",
       "missing %  1.221739  1.207696  1.193653  1.137481  1.137481  1.123438   \n",
       "\n",
       "             fun1_1    amb2_1  field_cd  pf_o_att  pf_o_sin  pf_o_int  \\\n",
       "missing %  1.123438  1.123438  1.053223  1.025137  1.025137  1.025137   \n",
       "\n",
       "           imprelig      from   museums      goal   imprace    go_out  \\\n",
       "missing %  0.997051  0.997051  0.997051  0.997051  0.997051  0.997051   \n",
       "\n",
       "             sports  tvsports  exercise    dining       art    hiking  \\\n",
       "missing %  0.997051  0.997051  0.997051  0.997051  0.997051  0.997051   \n",
       "\n",
       "               yoga    fun2_1  intel2_1   sinc2_1   attr2_1  intel1_1  \\\n",
       "missing %  0.997051  0.997051  0.997051  0.997051  0.997051  0.997051   \n",
       "\n",
       "            sinc1_1    gaming   attr1_1  shopping     music  concerts  \\\n",
       "missing %  0.997051  0.997051  0.997051  0.997051  0.997051  0.997051   \n",
       "\n",
       "             movies   theater   reading  clubbing        tv    race_o  \\\n",
       "missing %  0.997051  0.997051  0.997051  0.997051  0.997051  0.800449   \n",
       "\n",
       "               race     field      pid        id  iid  income  zipcode  \\\n",
       "missing %  0.800449  0.800449  0.14043  0.014043  0.0     0.0      0.0   \n",
       "\n",
       "           tuition  mn_sat  dec_o  samerace  match  partner  order  position  \\\n",
       "missing %      0.0     0.0    0.0       0.0    0.0      0.0    0.0       0.0   \n",
       "\n",
       "           round  wave  condtn  idg  gender  dec  \n",
       "missing %    0.0   0.0     0.0  0.0     0.0  0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((train_df.isna().sum()/len(train_df)) * 100).to_frame(name='missing %').sort_values(by=['missing %'], ascending=False).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e240c",
   "metadata": {},
   "source": [
    "Okay! so we have lots of columns with missing values (_as also already shown in EDA too_). Let's see what are the typical ways to deal with them\n",
    "\n",
    "There are multiple ways to compute the missing values. Although most of them are `distance based` and only work on _numeric_ features. Missing values are computed on training data only otherwise it can cause _Data Leakage_ (accidentally share the information between the `test` and `train` datasets) as well. List below are the typical ways we use to deal with missing values:\n",
    "\n",
    "1. Check manually what values are missing and correct them. We can check if there is a pattern to the missing values, think about the possible reasons why it happened in the first place\n",
    "\n",
    "2. Also, it is know practice to drop the columns if they have more than ~50% of the missing values\n",
    "\n",
    "3. Deleting rows with missing values - Deleting rows (if we have enough data) or column (if column is not important intutive idea from domain knowledge)\n",
    "\n",
    "4. Impute missing values for continuous variable - mean/median - without causing _data leakage_\n",
    "\n",
    "5. Impute missing values for categorical variable - mode ('most_frequent' or 'constant' strategy)\n",
    "\n",
    "6. Other Imputation Methods - interpolation (provide missing term using nearby trends, newton forward/backward formula, for multivariate - nearest neighbour interpolation, gaussian, polynomial (good for time series interpolation))\n",
    "\n",
    "7. Using Algorithms that support missing values (k-NN - based on k, get the closest rows using euclidean distance and take the average of there missing value column values)\n",
    "\n",
    "> Note: Imputation: Replace missing datas with statistical values. sklearn has a [`Imputation` module (sklearn.impute)](https://scikit-learn.org/stable/modules/impute.html#impute) which is quite helpful here.\n",
    "\n",
    "#### How to impute the missing data ? What do we need ?\n",
    "\n",
    "- A generalized model for missing values so that if values are missing in test data the model will not break\n",
    "- Although the mordern tree based algorithms manages the missing values by default using techniques such as `fragments` and `surrogate splits` so while using these algos we do not need to worry about missing values\n",
    "- We can make a gernalized imputation model which can deal with all the unexpected missing values if required\n",
    "\n",
    "---\n",
    "\n",
    "#### Some of the imputers being used from [_sklearn.impute_](https://scikit-learn.org/stable/modules/impute.html#impute) module\n",
    "\n",
    "##### [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer)\n",
    "\n",
    "- Replace `NaN` (`np.nan`) by the `mean`, `median`, `most_frequent` or `constant`\n",
    "\n",
    "\n",
    "##### [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer)\n",
    "\n",
    "- Replace your missing values by closest ones\n",
    "- Imputation for completing missing values using k-Nearest Neighbors\n",
    "- Each sample’s missing values are imputed using the _mean_ value from `n_neighbors` nearest neighbors found in the training set. Two samples are close if the features that neither is missing are close\n",
    "\n",
    "##### [MissingIndicator](https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html#sklearn.impute.MissingIndicator)\n",
    "\n",
    "- Position of missing values by a `boolean` mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1751b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold for missing value - remove all columns which has greater than 50% of missing values\n",
    "__missing_threshold = float(50)\n",
    "\n",
    "missing_df = ((train_df.isna().sum()/len(train_df)) * 100).to_frame(name='missing').sort_values(by=['missing'], ascending=False).query(\"missing > {}\".format(__missing_threshold))\n",
    "missing_cols = missing_df.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f235ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age',\n",
       " 'age_o',\n",
       " 'amb',\n",
       " 'amb1_1',\n",
       " 'amb1_2',\n",
       " 'amb2_1',\n",
       " 'amb2_2',\n",
       " 'amb3_1',\n",
       " 'amb3_2',\n",
       " 'amb4_1',\n",
       " 'amb4_2',\n",
       " 'amb5_1',\n",
       " 'amb5_2',\n",
       " 'amb_o',\n",
       " 'art',\n",
       " 'attr',\n",
       " 'attr1_1',\n",
       " 'attr1_2',\n",
       " 'attr2_1',\n",
       " 'attr2_2',\n",
       " 'attr3_1',\n",
       " 'attr3_2',\n",
       " 'attr4_1',\n",
       " 'attr4_2',\n",
       " 'attr5_1',\n",
       " 'attr5_2',\n",
       " 'attr_o',\n",
       " 'career',\n",
       " 'career_c',\n",
       " 'clubbing',\n",
       " 'concerts',\n",
       " 'condtn',\n",
       " 'date',\n",
       " 'dec',\n",
       " 'dec_o',\n",
       " 'dining',\n",
       " 'exercise',\n",
       " 'exphappy',\n",
       " 'field',\n",
       " 'field_cd',\n",
       " 'from',\n",
       " 'fun',\n",
       " 'fun1_1',\n",
       " 'fun1_2',\n",
       " 'fun2_1',\n",
       " 'fun2_2',\n",
       " 'fun3_1',\n",
       " 'fun3_2',\n",
       " 'fun4_1',\n",
       " 'fun4_2',\n",
       " 'fun5_1',\n",
       " 'fun5_2',\n",
       " 'fun_o',\n",
       " 'gaming',\n",
       " 'gender',\n",
       " 'go_out',\n",
       " 'goal',\n",
       " 'hiking',\n",
       " 'id',\n",
       " 'idg',\n",
       " 'iid',\n",
       " 'imprace',\n",
       " 'imprelig',\n",
       " 'income',\n",
       " 'int_corr',\n",
       " 'intel',\n",
       " 'intel1_1',\n",
       " 'intel1_2',\n",
       " 'intel2_1',\n",
       " 'intel2_2',\n",
       " 'intel3_1',\n",
       " 'intel3_2',\n",
       " 'intel4_1',\n",
       " 'intel4_2',\n",
       " 'intel5_1',\n",
       " 'intel5_2',\n",
       " 'intel_o',\n",
       " 'length',\n",
       " 'like',\n",
       " 'like_o',\n",
       " 'match',\n",
       " 'match_es',\n",
       " 'met',\n",
       " 'met_o',\n",
       " 'mn_sat',\n",
       " 'movies',\n",
       " 'museums',\n",
       " 'music',\n",
       " 'numdat_2',\n",
       " 'order',\n",
       " 'partner',\n",
       " 'pf_o_amb',\n",
       " 'pf_o_att',\n",
       " 'pf_o_fun',\n",
       " 'pf_o_int',\n",
       " 'pf_o_sha',\n",
       " 'pf_o_sin',\n",
       " 'pid',\n",
       " 'positin1',\n",
       " 'position',\n",
       " 'prob',\n",
       " 'prob_o',\n",
       " 'race',\n",
       " 'race_o',\n",
       " 'reading',\n",
       " 'round',\n",
       " 'samerace',\n",
       " 'satis_2',\n",
       " 'shar',\n",
       " 'shar1_1',\n",
       " 'shar1_2',\n",
       " 'shar2_1',\n",
       " 'shar2_2',\n",
       " 'shar4_1',\n",
       " 'shar4_2',\n",
       " 'shar_o',\n",
       " 'shopping',\n",
       " 'sinc',\n",
       " 'sinc1_1',\n",
       " 'sinc1_2',\n",
       " 'sinc2_1',\n",
       " 'sinc2_2',\n",
       " 'sinc3_1',\n",
       " 'sinc3_2',\n",
       " 'sinc4_1',\n",
       " 'sinc4_2',\n",
       " 'sinc5_1',\n",
       " 'sinc5_2',\n",
       " 'sinc_o',\n",
       " 'sports',\n",
       " 'theater',\n",
       " 'tuition',\n",
       " 'tv',\n",
       " 'tvsports',\n",
       " 'undergra',\n",
       " 'wave',\n",
       " 'yoga',\n",
       " 'zipcode'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_df.columns.to_list()) - set(missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputate missing values\n",
    "def imputate_missing_features(data, missing_threshold = 50):\n",
    "\n",
    "    # threshold for missing value - remove all columns which has greater than 50% of missing values\n",
    "    __missing_threshold = missing_threshold\n",
    "\n",
    "    missing_df = ((data.isna().sum()/len(data)) * 100).to_frame(name='missing').sort_values(by=['missing'], ascending=False).query(\"missing > {}\".format(__missing_threshold))\n",
    "    missing_cols = missing_df.index.to_list()\n",
    "\n",
    "    cols_to_use = list(set(data.columns.to_list()) - set(missing_cols))\n",
    "\n",
    "    num_features = make_column_selector(cols_to_use, dtype_include=np.number) # get all numeric data\n",
    "    cat_features = make_column_selector(dtype_exclude=np.number)\n",
    "\n",
    "    num_pipe = make_pipeline(\n",
    "        KNNImputer(),\n",
    "        StandardScaler()\n",
    "    )\n",
    "\n",
    "    cat_pipe = make_pipeline(\n",
    "        SimpleImputer(strategy = 'most_frequent'),\n",
    "        OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    )\n",
    "\n",
    "    col_trans = make_column_transformer(\n",
    "        (num_pipe, num_features),\n",
    "        (cat_pipe, cat_features)\n",
    "    )\n",
    "\n",
    "    model_pipe = make_pipeline(\n",
    "        col_trans, \n",
    "        LogisticRegression()\n",
    "    )\n",
    "\n",
    "    model_pipe.get_params\n",
    "\n",
    "param_grid = {\n",
    "    'columntransformer__pipeline-1__knnimputer__n_neighbors': [1,5],\n",
    "    'logisticregression__C': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model_pipe, param_grid, cv=10, scoring='accuracy', verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fe3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        ('features', SimpleImputer(strategy='mean')), \n",
    "        ('indicators', MissingIndicator(missing_values=np.nan, features=\"all\", error_on_new=False)\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60e7d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.select_dtypes(include='number'), train_df['dec']\n",
    "\n",
    "#X_train = X_train.loc[:, ~X_train.columns.isin(['dec'])] # keep all but 'dec' column\n",
    "X_train.drop(['dec'], axis=1, inplace=True) # drop 'dec' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transformer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0ca1c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('knnimputer',\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  ('standardscaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f8a31365160>),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehotencoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f8a445c3b80>)])),\n",
       "                ('logisticregression', LogisticRegression())])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "[CV 1/10; 1/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1\n",
      "[CV 1/10; 1/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1;, score=0.877 total time=  18.3s\n",
      "[CV 2/10; 1/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1\n",
      "[CV 2/10; 1/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1;, score=0.861 total time=  17.8s\n",
      "[CV 3/10; 1/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1\n",
      "[CV 3/10; 1/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1;, score=0.864 total time=  17.7s\n",
      "[CV 4/10; 1/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1\n",
      "[CV 4/10; 1/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1;, score=0.881 total time=  18.0s\n",
      "[CV 5/10; 1/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1\n",
      "[CV 5/10; 1/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1;, score=0.864 total time=  17.9s\n",
      "[CV 6/10; 1/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1\n",
      "[CV 6/10; 1/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1;, score=0.890 total time=  17.9s\n",
      "[CV 7/10; 1/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1\n",
      "[CV 7/10; 1/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1;, score=0.895 total time=  18.1s\n",
      "[CV 8/10; 1/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1\n",
      "[CV 8/10; 1/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1;, score=0.882 total time=  18.1s\n",
      "[CV 9/10; 1/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1\n",
      "[CV 9/10; 1/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1;, score=0.885 total time=  17.3s\n",
      "[CV 10/10; 1/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1\n",
      "[CV 10/10; 1/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.1;, score=0.872 total time=  17.0s\n",
      "[CV 1/10; 2/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5\n",
      "[CV 1/10; 2/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5;, score=0.877 total time=  16.6s\n",
      "[CV 2/10; 2/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5\n",
      "[CV 2/10; 2/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5;, score=0.861 total time=  17.0s\n",
      "[CV 3/10; 2/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5\n",
      "[CV 3/10; 2/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5;, score=0.861 total time=  17.2s\n",
      "[CV 4/10; 2/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5\n",
      "[CV 4/10; 2/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5;, score=0.881 total time=  17.5s\n",
      "[CV 5/10; 2/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5\n",
      "[CV 5/10; 2/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5;, score=0.867 total time=  17.1s\n",
      "[CV 6/10; 2/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5\n",
      "[CV 6/10; 2/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5;, score=0.892 total time=  17.2s\n",
      "[CV 7/10; 2/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5\n",
      "[CV 7/10; 2/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5;, score=0.895 total time=  16.8s\n",
      "[CV 8/10; 2/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5\n",
      "[CV 8/10; 2/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5;, score=0.885 total time=  17.7s\n",
      "[CV 9/10; 2/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5\n",
      "[CV 9/10; 2/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5;, score=0.885 total time=  17.8s\n",
      "[CV 10/10; 2/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5\n",
      "[CV 10/10; 2/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=0.5;, score=0.878 total time=  18.1s\n",
      "[CV 1/10; 3/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1\n",
      "[CV 1/10; 3/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1;, score=0.874 total time=  16.8s\n",
      "[CV 2/10; 3/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1\n",
      "[CV 2/10; 3/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1;, score=0.862 total time=  17.1s\n",
      "[CV 3/10; 3/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1\n",
      "[CV 3/10; 3/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1;, score=0.858 total time=  18.4s\n",
      "[CV 4/10; 3/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1\n",
      "[CV 4/10; 3/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1;, score=0.879 total time=  17.9s\n",
      "[CV 5/10; 3/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1\n",
      "[CV 5/10; 3/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1;, score=0.867 total time=  17.3s\n",
      "[CV 6/10; 3/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1\n",
      "[CV 6/10; 3/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1;, score=0.890 total time=  17.2s\n",
      "[CV 7/10; 3/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1\n",
      "[CV 7/10; 3/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1;, score=0.896 total time=  18.2s\n",
      "[CV 8/10; 3/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1\n",
      "[CV 8/10; 3/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1;, score=0.885 total time=  18.0s\n",
      "[CV 9/10; 3/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1\n",
      "[CV 9/10; 3/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1;, score=0.885 total time=  17.5s\n",
      "[CV 10/10; 3/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1\n",
      "[CV 10/10; 3/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=1, logisticregression__C=1;, score=0.878 total time=  17.3s\n",
      "[CV 1/10; 4/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1\n",
      "[CV 1/10; 4/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1;, score=0.877 total time=  23.7s\n",
      "[CV 2/10; 4/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1\n",
      "[CV 2/10; 4/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1;, score=0.868 total time=  24.0s\n",
      "[CV 3/10; 4/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1\n",
      "[CV 3/10; 4/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1;, score=0.871 total time=  24.8s\n",
      "[CV 4/10; 4/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1\n",
      "[CV 4/10; 4/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1;, score=0.885 total time=  25.0s\n",
      "[CV 5/10; 4/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1\n",
      "[CV 5/10; 4/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1;, score=0.869 total time=  24.8s\n",
      "[CV 6/10; 4/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1\n",
      "[CV 6/10; 4/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1;, score=0.890 total time=  24.6s\n",
      "[CV 7/10; 4/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1\n",
      "[CV 7/10; 4/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1;, score=0.896 total time=  24.1s\n",
      "[CV 8/10; 4/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1\n",
      "[CV 8/10; 4/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1;, score=0.883 total time=  24.4s\n",
      "[CV 9/10; 4/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1\n",
      "[CV 9/10; 4/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1;, score=0.879 total time=  23.8s\n",
      "[CV 10/10; 4/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1\n",
      "[CV 10/10; 4/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.1;, score=0.867 total time=  23.2s\n",
      "[CV 1/10; 5/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5\n",
      "[CV 1/10; 5/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5;, score=0.879 total time=  23.7s\n",
      "[CV 2/10; 5/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5\n",
      "[CV 2/10; 5/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5;, score=0.867 total time=  24.0s\n",
      "[CV 3/10; 5/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5\n",
      "[CV 3/10; 5/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5;, score=0.868 total time=  24.1s\n",
      "[CV 4/10; 5/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5\n",
      "[CV 4/10; 5/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5;, score=0.879 total time=  24.1s\n",
      "[CV 5/10; 5/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5\n",
      "[CV 5/10; 5/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5;, score=0.872 total time=  23.8s\n",
      "[CV 6/10; 5/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5\n",
      "[CV 6/10; 5/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5;, score=0.890 total time=  23.9s\n",
      "[CV 7/10; 5/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5\n",
      "[CV 7/10; 5/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5;, score=0.896 total time=  24.0s\n",
      "[CV 8/10; 5/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5\n",
      "[CV 8/10; 5/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5;, score=0.886 total time=  24.0s\n",
      "[CV 9/10; 5/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5\n",
      "[CV 9/10; 5/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5;, score=0.879 total time=  24.4s\n",
      "[CV 10/10; 5/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5\n",
      "[CV 10/10; 5/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=0.5;, score=0.874 total time=  23.7s\n",
      "[CV 1/10; 6/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1\n",
      "[CV 1/10; 6/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1;, score=0.875 total time=  24.2s\n",
      "[CV 2/10; 6/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1\n",
      "[CV 2/10; 6/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1;, score=0.865 total time=  23.8s\n",
      "[CV 3/10; 6/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1\n",
      "[CV 3/10; 6/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1;, score=0.868 total time=  24.0s\n",
      "[CV 4/10; 6/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1\n",
      "[CV 4/10; 6/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1;, score=0.878 total time=  24.1s\n",
      "[CV 5/10; 6/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1\n",
      "[CV 5/10; 6/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1;, score=0.871 total time=  24.3s\n",
      "[CV 6/10; 6/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1\n",
      "[CV 6/10; 6/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1;, score=0.890 total time=  24.3s\n",
      "[CV 7/10; 6/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1\n",
      "[CV 7/10; 6/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1;, score=0.895 total time=  23.9s\n",
      "[CV 8/10; 6/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1\n",
      "[CV 8/10; 6/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1;, score=0.889 total time=  24.3s\n",
      "[CV 9/10; 6/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1\n",
      "[CV 9/10; 6/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1;, score=0.881 total time=  23.8s\n",
      "[CV 10/10; 6/6] START columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1\n",
      "[CV 10/10; 6/6] END columntransformer__pipeline-1__knnimputer__n_neighbors=5, logisticregression__C=1;, score=0.876 total time=  23.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                                          KNNImputer()),\n",
       "                                                                                         (&#x27;standardscaler&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8a31365160&gt;),\n",
       "                                                                        (&#x27;pipeline-2&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;mos...t&#x27;)),\n",
       "                                                                                         (&#x27;onehotencoder&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8a445c3b80&gt;)])),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             param_grid={&#x27;columntransformer__pipeline-1__knnimputer__n_neighbors&#x27;: [1,\n",
       "                                                                                    5],\n",
       "                         &#x27;logisticregression__C&#x27;: [0.1, 0.5, 1]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                                          KNNImputer()),\n",
       "                                                                                         (&#x27;standardscaler&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8a31365160&gt;),\n",
       "                                                                        (&#x27;pipeline-2&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;mos...t&#x27;)),\n",
       "                                                                                         (&#x27;onehotencoder&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8a445c3b80&gt;)])),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             param_grid={&#x27;columntransformer__pipeline-1__knnimputer__n_neighbors&#x27;: [1,\n",
       "                                                                                    5],\n",
       "                         &#x27;logisticregression__C&#x27;: [0.1, 0.5, 1]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8a31365160&gt;),\n",
       "                                                 (&#x27;pipeline-2&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehotencoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8a445c3b80&gt;)])),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;knnimputer&#x27;, KNNImputer()),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8a31365160&gt;),\n",
       "                                (&#x27;pipeline-2&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8a445c3b80&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-1</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8a31365160&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-2</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8a445c3b80&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                                         Pipeline(steps=[('knnimputer',\n",
       "                                                                                          KNNImputer()),\n",
       "                                                                                         ('standardscaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f8a31365160>),\n",
       "                                                                        ('pipeline-2',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(strategy='mos...t')),\n",
       "                                                                                         ('onehotencoder',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f8a445c3b80>)])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             param_grid={'columntransformer__pipeline-1__knnimputer__n_neighbors': [1,\n",
       "                                                                                    5],\n",
       "                         'logisticregression__C': [0.1, 0.5, 1]},\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feat = make_column_selector(dtype_include=np.number)\n",
    "cat_feat = make_column_selector(dtype_exclude=np.number)\n",
    "\n",
    "num_pipe = make_pipeline(\n",
    "    KNNImputer(),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy = 'most_frequent'),\n",
    "    OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    ")\n",
    "\n",
    "col_trans = make_column_transformer(\n",
    "    (num_pipe, num_feat),\n",
    "    (cat_pipe, cat_feat)\n",
    ")\n",
    "\n",
    "model_pipe = make_pipeline(\n",
    "    col_trans, \n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "model_pipe.get_params\n",
    "\n",
    "param_grid = {\n",
    "    'columntransformer__pipeline-1__knnimputer__n_neighbors': [1,5],\n",
    "    'logisticregression__C': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model_pipe, param_grid, cv=10, scoring='accuracy', verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e587395f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer__pipeline-1__knnimputer__n_neighbors': 5,\n",
       " 'logisticregression__C': 0.5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8790899743133144"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f939fc",
   "metadata": {},
   "source": [
    "Below mentioned are the articles, blogs, papers and other resources which we took inspiration from or we think are useful for future use case\n",
    "\n",
    "#### References\n",
    "\n",
    "- [_Getting Started with Data Preprocessing in Python_](https://www.section.io/engineering-education/data-preprocessing-python/)\n",
    "- [_Data Preprocessing in Python_](https://medium.datadriveninvestor.com/data-preprocessing-3cd01eefd438)\n",
    "- [_Data Pre-processing in Python for Beginner_](https://medium.com/data-science-indo/data-preparation-in-python-for-beginner-d3e1e60c03a6)\n",
    "- [_Data Preprocessing using Python_](https://medium.com/@suneet.bhopal/data-preprocessing-using-python-1bfee9268fb3)\n",
    "- [_Data preprocessing for Machine Learning in Python_](https://towardsdatascience.com/data-preprocessing-for-machine-learning-in-python-2d465f83f18c)\n",
    "- [_Data Preprocessing in Machine Learning_](https://www.analytixlabs.co.in/blog/data-preprocessing-in-machine-learning/)\n",
    "- [_Normalization vs Standardization — Quantitative analysis_](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf)\n",
    "- [__]()\n",
    "- [__]()\n",
    "- [__]()\n",
    "- [__]()\n",
    "- [__]()\n",
    "- [__]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682e7ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b33028dfef90447248446bd6a115b2c1f87c179fa7c4ab6e59f7d48c9bbeef80"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
