{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664f2f67-d217-4a9c-b794-fa7fecd115a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # disable warnings\n",
    "\n",
    "from os import getcwd\n",
    "from os.path import join, abspath, pardir, exists\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle, json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "# scipy\n",
    "from scipy.stats import ttest_ind, chi2_contingency, boxcox, skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.impute import KNNImputer, SimpleImputer, MissingIndicator\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.pipeline import FeatureUnion, make_pipeline, Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import make_column_selector, make_column_transformer, make_column_transformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer # enable experimental imputer\n",
    "from sklearn.impute import IterativeImputer               # sample imputation\n",
    "from sklearn import preprocessing                         # encoders, transformations\n",
    "from sklearn.model_selection import cross_validate        # cross-validation, model evaluation\n",
    "from sklearn.model_selection import GridSearchCV          # hyper-parameter tuning\n",
    "from sklearn.linear_model import LogisticRegression       # logistic regression model\n",
    "from sklearn.svm import SVC                               # support vector machine model\n",
    "from sklearn.neighbors import KNeighborsClassifier        # k-nearest neighbours model\n",
    "from sklearn.ensemble import GradientBoostingClassifier   # gradient boosting model\n",
    "from sklearn.ensemble import VotingClassifier             # voting ensemble model\n",
    "from sklearn.ensemble import StackingClassifier           # stacking ensemble model\n",
    "\n",
    "\n",
    "# statsmodel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# IPython\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83b4df",
   "metadata": {},
   "source": [
    "##### Config settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4894fe-4fc0-4580-b2df-275bbdfb82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = abspath(join(join(getcwd(), pardir), pardir))\n",
    "data_dir = join(parent_dir, \"data\")\n",
    "model_dir = join(parent_dir, \"models\")\n",
    "data_file = join(data_dir, \"test.csv\")\n",
    "\n",
    "# For IPython\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # To show all output after each cell execution (instead of the last output)\n",
    "\n",
    "# For pandas\n",
    "\n",
    "pd.options.display.max_columns = 200 # display upto 200 columns (instead of default 20)\n",
    "pd.options.display.max_rows = 200 # display upto 200 rows (instead of default 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627281a6",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61424211",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features = [\n",
    "    ['iid', 'int16'], ['gender', 'bool'],\n",
    "    ['wave', 'int16'], ['position', 'int16'],\n",
    "    ['order', 'int16'], ['pid', 'int16'],\n",
    "    ['age_o', 'int16'], ['race_o', 'category'],\n",
    "    ['pf_o_att', 'int16'], ['pf_o_sin', 'int16'],\n",
    "    ['pf_o_int', 'int16'], ['pf_o_fun', 'int16'],\n",
    "    ['pf_o_amb', 'int16'], ['pf_o_sha', 'int16'],\n",
    "    ['dec_o', 'bool'], ['attr_o', 'int16'], ['sinc_o', 'int16'], \n",
    "    ['intel_o', 'int16'], ['fun_o', 'int16'], ['amb_o', 'int16'], \n",
    "    ['shar_o', 'int16'], ['like_o', 'int16'],\n",
    "    ['prob_o', 'int16'], ['met_o', 'bool'], ['age', 'int16'], ['field_cd', 'category'], ['race', 'category'],\n",
    "    ['imprace', 'int16'], ['imprelig', 'int16'], ['goal', 'category'], ['date', 'int16'],\n",
    "    ['go_out', 'int16'], ['career_c', 'category'], ['sports', 'int16'], ['tvsports', 'int16'], ['exercise', 'int16'],\n",
    "    ['dining', 'int16'], ['museums', 'int16'], ['art', 'int16'], ['hiking', 'int16'],\n",
    "    ['gaming', 'int16'], ['clubbing', 'int16'], ['reading', 'int16'], ['tv', 'int16'],\n",
    "    ['theater', 'int16'], ['movies', 'int16'], ['concerts', 'int16'], ['music', 'int16'],\n",
    "    ['shopping', 'int16'], ['yoga', 'int16'], ['exphappy', 'int16'], ['expnum', 'int16'],\n",
    "    ['attr1_1', 'int16'], ['sinc1_1', 'int16'], ['intel1_1', 'int16'], ['fun1_1', 'int16'],\n",
    "    ['amb1_1', 'int16'], ['shar1_1', 'int16'], ['attr3_1', 'int16'], ['sinc3_1', 'int16'],\n",
    "    ['fun3_1', 'int16'], ['intel3_1', 'int16'], ['amb3_1', 'int16'], ['dec', 'bool'],\n",
    "    ['attr', 'int16'], ['sinc', 'int16'], ['intel', 'int16'], ['fun', 'int16'],\n",
    "    ['amb', 'int16'], ['shar', 'int16'], ['like', 'int16'], ['prob', 'int16'],\n",
    "    ['met', 'int16'], ['match_es', 'int16'], ['satis_2', 'int16'], ['length', 'int16'],\n",
    "    ['numdat_2', 'int16']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46177fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save model as a pickle file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "def load_model(file_path: str):\n",
    "    \"\"\"\n",
    "    Load model from a pickle file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def dataframe_to_csv(df: pd.DataFrame, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save dataframe as .csv file\n",
    "    \"\"\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def plot_distribution(data, bins, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Plot distribution functions\n",
    "    \"\"\"\n",
    "    ax = sns.distplot(\n",
    "        data,\n",
    "        bins=bins,\n",
    "        hist_kws={\n",
    "            \"linewidth\": 1,\n",
    "            'edgecolor': 'black',\n",
    "            'alpha': 1.0\n",
    "            },\n",
    "        kde=False\n",
    "    )\n",
    "    _ = ax.set_title(title)\n",
    "    _ = ax.set_xlabel(xlabel)\n",
    "    _ = ax.set_ylabel(ylabel)\n",
    "\n",
    "def plot_relationship(x, y, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Plot relationship between two features\n",
    "    \"\"\"\n",
    "    ax = sns.barplot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        orient='h'\n",
    "    )\n",
    "    _ = ax.set_title(title)\n",
    "    _ = ax.set_xlabel(xlabel)\n",
    "    _ = ax.set_ylabel(ylabel)\n",
    "\n",
    "def print_moments(title, feature):\n",
    "    \"\"\"\n",
    "    Print a feature's mean, standard deviation, skewness and kurtosis\n",
    "    \"\"\"\n",
    "    print(title)\n",
    "    print('Mean: '+'{:>18.2f}'.format(feature.mean()))\n",
    "    print('Standard deviation: '+'{:.2f}'.format(feature.std()))\n",
    "    print('Skewness: '+'{:>14.2f}'.format(feature.skew()))\n",
    "    print('Kurtosis: '+'{:>14.2f}'.format(feature.kurtosis()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea30025",
   "metadata": {},
   "source": [
    "#### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file, encoding= 'ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499547fe",
   "metadata": {},
   "source": [
    "## Test Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a3839",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075aa23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gb = load_model(join(model_dir, \"clf_gb.pkl\"))\n",
    "clf_knn = load_model(join(model_dir, \"clf_knn.pkl\"))\n",
    "clf_logistic_regression = load_model(join(model_dir, \"clf_logistic_regression.pkl\"))\n",
    "clf_stacking = load_model(join(model_dir, \"clf_stacking.pkl\"))\n",
    "clf_svc = load_model(join(model_dir, \"clf_svc.pkl\"))\n",
    "clf_voting = load_model(join(model_dir, \"clf_voting.pkl\"))\n",
    "col_trans = load_model(join(model_dir, \"col_trans.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6446811",
   "metadata": {},
   "source": [
    "##### Basic checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64442b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dec'].isnull().any()\n",
    "((df.isna().sum()/len(df)) * 100).to_frame(name='missing %').sort_values(by=['missing %'], ascending=False).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce29f3",
   "metadata": {},
   "source": [
    "##### Imputate missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = np.around(col_trans.transform(df))\n",
    "test_df = pd.DataFrame(scaled, columns=df.columns)\n",
    "test_df = test_df.astype({feature: datatype if all(test_df[feature].notna().values) else 'float32' if datatype == 'int16' else datatype for (feature, datatype) in relevant_features})\n",
    "test_df.shape\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().any() # check missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3cf6c",
   "metadata": {},
   "source": [
    "Imputation model transformed `test` data successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a018130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(data):\n",
    "    \"\"\"\n",
    "    Pre-processing Pipeline for testing data\n",
    "    \"\"\"\n",
    "    # Encode nominal features using one-hot encoding\n",
    "    # features_nominal = test_df.dtypes[test_df.dtypes == 'category'].index.values\n",
    "    # data = pd.get_dummies(test_df, prefix=features_nominal)\n",
    "\n",
    "    # Calculate the average attribute ratings for each subject\n",
    "    subject_attractiveness_mean = data[['iid', 'attr_o']].groupby(['iid']).mean()['attr_o']\n",
    "    subject_sincerity_mean = data[['iid', 'sinc_o']].groupby(['iid']).mean()['sinc_o']\n",
    "    subject_intelligence_mean = data[['iid', 'intel_o']].groupby(['iid']).mean()['intel_o']\n",
    "    subject_fun_mean = data[['iid', 'fun_o']].groupby(['iid']).mean()['fun_o']\n",
    "    subject_ambition_mean = data[['iid', 'amb_o']].groupby(['iid']).mean()['amb_o']\n",
    "    subject_shared_interest_mean = data[['iid', 'shar_o']].groupby(['iid']).mean()['shar_o']\n",
    "\n",
    "    # Insert average attribute ratings into dataframe\n",
    "    data = data.merge(\n",
    "        right=subject_attractiveness_mean,\n",
    "        how='inner',\n",
    "        on='iid'\n",
    "    ).rename(columns={\n",
    "        'attr_o_x': 'attr_o',\n",
    "        'attr_o_y': 'subject_attractiveness_mean'\n",
    "    })\n",
    "    data = data.merge(\n",
    "        right=subject_sincerity_mean,\n",
    "        how='inner',\n",
    "        on='iid'\n",
    "    ).rename(columns={\n",
    "        'sinc_o_x': 'sinc_o',\n",
    "        'sinc_o_y': 'subject_sincerity_mean'\n",
    "    })\n",
    "    data = data.merge(\n",
    "        right=subject_intelligence_mean,\n",
    "        how='inner',\n",
    "        on='iid'\n",
    "    ).rename(columns={\n",
    "        'intel_o_x': 'intel_o',\n",
    "        'intel_o_y': 'subject_intelligence_mean'\n",
    "    })\n",
    "    data = data.merge(\n",
    "        right=subject_fun_mean,\n",
    "        how='inner',\n",
    "        on='iid'\n",
    "    ).rename(columns={\n",
    "        'fun_o_x': 'fun_o',\n",
    "        'fun_o_y': 'subject_fun_mean'\n",
    "    })\n",
    "    data = data.merge(\n",
    "        right=subject_ambition_mean,\n",
    "        how='inner',\n",
    "        on='iid'\n",
    "    ).rename(columns={\n",
    "        'amb_o_x': 'amb_o',\n",
    "        'amb_o_y': 'subject_ambition_mean'\n",
    "    })\n",
    "    data = data.merge(\n",
    "        right=subject_shared_interest_mean,\n",
    "        how='inner',\n",
    "        on='iid'\n",
    "    ).rename(columns={\n",
    "        'shar_o_x': 'shar_o',\n",
    "        'shar_o_y': 'subject_shared_interest_mean'\n",
    "    })\n",
    "\n",
    "    # Calculate difference between subject and partner's ages\n",
    "    data['age_difference'] = abs(data['age'] - data['age_o'])\n",
    "\n",
    "    #Calculate difference between subject's attribute ratings and partner's attributes ratings\n",
    "    data['attractiveness_difference'] = abs(data['attr'] - data['attr_o'])\n",
    "    data['sincerity_difference'] = abs(data['sinc'] - data['sinc_o'])\n",
    "    data['intelligence_difference'] = abs(data['intel'] - data['intel_o'])\n",
    "    data['fun_difference'] = abs(data['fun'] - data['fun_o'])\n",
    "    data['ambition_difference'] = abs(data['amb'] - data['amb_o'])\n",
    "    data['shared_interest_difference'] = abs(data['shar'] - data['shar_o'])\n",
    "\n",
    "    #Scale normal features to zero mean and unit variance\n",
    "    features_normal = [\n",
    "        'attr_o',\n",
    "        'sinc_o',\n",
    "        'intel_o',\n",
    "        'fun_o',\n",
    "        'amb_o',\n",
    "        'shar_o',\n",
    "        'age_difference',\n",
    "        'attractiveness_difference',\n",
    "        'sincerity_difference',\n",
    "        'intelligence_difference',\n",
    "        'fun_difference',\n",
    "        'ambition_difference',\n",
    "        'shared_interest_difference'\n",
    "    ]\n",
    "\n",
    "    data[features_normal] = data[features_normal].apply(lambda x: preprocessing.scale(x))\n",
    "\n",
    "    # Drop some features\n",
    "    # Drop irrelevant features which contain no information about the target variable\n",
    "    features_no_information = [\n",
    "        'iid',\n",
    "        'pid',\n",
    "        'wave',\n",
    "        'position',\n",
    "        'order'\n",
    "    ]\n",
    "    # Drop features that are known in the future\n",
    "    features_future_information = [\n",
    "        'dec',\n",
    "        #'dec_o',\n",
    "        'like',\n",
    "        'prob',\n",
    "        'like_o',\n",
    "        'prob_o'\n",
    "    ]\n",
    "\n",
    "    # Drop features that have low variance\n",
    "    feature_variances = data.std().sort_values(ascending=True)\n",
    "    features_low_variance = feature_variances[feature_variances < 0.1].index.values.tolist()\n",
    "\n",
    "    # Drop features that have weak correlation with target variable\n",
    "    correlations = data.corr().abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "    correlations = correlations[correlations != 1]\n",
    "    partner_decision_correlations = correlations.loc['dec_o']\n",
    "    features_weak_correlation = partner_decision_correlations[partner_decision_correlations < 0.1].axes[0].to_list()\n",
    "    features_weak_correlation = list(set(features_weak_correlation) - set(features_future_information) - set(features_no_information))\n",
    "\n",
    "    # Drop features that were used in interaction variables\n",
    "    features_interaction = [\n",
    "        'age',\n",
    "        'age_o',\n",
    "    ]\n",
    "\n",
    "    features_remove = features_no_information + features_future_information + features_low_variance + features_weak_correlation + features_interaction\n",
    "    data.drop(columns=features_remove, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240eb119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({feature: datatype if all(df[feature].notna().values) else 'float32' if datatype == 'int16' else datatype for (feature, datatype) in relevant_features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = col_trans.transform(df)\n",
    "test_df = pd.DataFrame(scaled, columns=df.columns)\n",
    "test_df.shape\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.astype({feature: datatype if all(test_df[feature].notna().values) else 'float32' if datatype == 'int16' else datatype for (feature, datatype) in relevant_features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode nominal features using one-hot encoding\n",
    "features_nominal = test_df.dtypes[test_df.dtypes == 'category'].index.values\n",
    "test_df = pd.get_dummies(test_df, prefix=features_nominal)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfefc09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = preprocessing_pipeline(test_df)\n",
    "test_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_df.loc[:,~test_df.columns.isin(['dec_o'])], test_df['dec_o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d409e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc146dc4",
   "metadata": {},
   "source": [
    "### 1. Testing on Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b120a6ce",
   "metadata": {},
   "source": [
    "#### 1.1. [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd65c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_logistic_regression.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d1417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b33028dfef90447248446bd6a115b2c1f87c179fa7c4ab6e59f7d48c9bbeef80"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
