{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664f2f67-d217-4a9c-b794-fa7fecd115a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # disable warnings\n",
    "\n",
    "from os import getcwd\n",
    "from os.path import join, abspath, pardir, exists\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle, json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "# scipy\n",
    "from scipy.stats import ttest_ind, chi2_contingency, boxcox, skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.impute import KNNImputer, SimpleImputer, MissingIndicator\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.pipeline import FeatureUnion, make_pipeline, Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import make_column_selector, make_column_transformer, make_column_transformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer # enable experimental imputer\n",
    "from sklearn.impute import IterativeImputer               # sample imputation\n",
    "from sklearn import preprocessing                         # encoders, transformations\n",
    "from sklearn.model_selection import cross_validate        # cross-validation, model evaluation\n",
    "from sklearn.model_selection import GridSearchCV          # hyper-parameter tuning\n",
    "from sklearn.linear_model import LogisticRegression       # logistic regression model\n",
    "from sklearn.svm import SVC                               # support vector machine model\n",
    "from sklearn.neighbors import KNeighborsClassifier        # k-nearest neighbours model\n",
    "from sklearn.ensemble import GradientBoostingClassifier   # gradient boosting model\n",
    "from sklearn.ensemble import VotingClassifier             # voting ensemble model\n",
    "from sklearn.ensemble import StackingClassifier           # stacking ensemble model\n",
    "\n",
    "\n",
    "# statsmodel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# IPython\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83b4df",
   "metadata": {},
   "source": [
    "##### Config settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df4894fe-4fc0-4580-b2df-275bbdfb82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = abspath(join(join(getcwd(), pardir), pardir))\n",
    "data_dir = join(parent_dir, \"data\")\n",
    "model_dir = join(parent_dir, \"models\")\n",
    "data_file = join(data_dir, \"preprocessed.csv\")\n",
    "\n",
    "# For IPython\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # To show all output after each cell execution (instead of the last output)\n",
    "\n",
    "# For pandas\n",
    "\n",
    "pd.options.display.max_columns = 200 # display upto 200 columns (instead of default 20)\n",
    "pd.options.display.max_rows = 200 # display upto 200 rows (instead of default 60)\n",
    "\n",
    "# random state\n",
    "__random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627281a6",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46177fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save model as a pickle file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "def load_model(file_path: str):\n",
    "    \"\"\"\n",
    "    Load model from a pickle file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def dataframe_to_csv(df: pd.DataFrame, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save dataframe as .csv file\n",
    "    \"\"\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def plot_distribution(data, bins, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Plot distribution functions\n",
    "    \"\"\"\n",
    "    ax = sns.distplot(\n",
    "        data,\n",
    "        bins=bins,\n",
    "        hist_kws={\n",
    "            \"linewidth\": 1,\n",
    "            'edgecolor': 'black',\n",
    "            'alpha': 1.0\n",
    "            },\n",
    "        kde=False\n",
    "    )\n",
    "    _ = ax.set_title(title)\n",
    "    _ = ax.set_xlabel(xlabel)\n",
    "    _ = ax.set_ylabel(ylabel)\n",
    "\n",
    "def plot_relationship(x, y, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Plot relationship between two features\n",
    "    \"\"\"\n",
    "    ax = sns.barplot(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        orient='h'\n",
    "    )\n",
    "    _ = ax.set_title(title)\n",
    "    _ = ax.set_xlabel(xlabel)\n",
    "    _ = ax.set_ylabel(ylabel)\n",
    "\n",
    "def print_moments(title, feature):\n",
    "    \"\"\"\n",
    "    Print a feature's mean, standard deviation, skewness and kurtosis\n",
    "    \"\"\"\n",
    "    print(title)\n",
    "    print('Mean: '+'{:>18.2f}'.format(feature.mean()))\n",
    "    print('Standard deviation: '+'{:.2f}'.format(feature.std()))\n",
    "    print('Skewness: '+'{:>14.2f}'.format(feature.skew()))\n",
    "    print('Kurtosis: '+'{:>14.2f}'.format(feature.kurtosis()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa8062",
   "metadata": {},
   "source": [
    "#### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ae3627-784c-4550-8dc4-ffd94bcbcbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>match_es</th>\n",
       "      <th>length</th>\n",
       "      <th>numdat_2</th>\n",
       "      <th>race_o_1.0</th>\n",
       "      <th>race_o_4.0</th>\n",
       "      <th>field_cd_2.0</th>\n",
       "      <th>field_cd_3.0</th>\n",
       "      <th>field_cd_4.0</th>\n",
       "      <th>field_cd_6.0</th>\n",
       "      <th>field_cd_7.0</th>\n",
       "      <th>field_cd_9.0</th>\n",
       "      <th>field_cd_11.0</th>\n",
       "      <th>field_cd_15.0</th>\n",
       "      <th>race_2.0</th>\n",
       "      <th>race_3.0</th>\n",
       "      <th>race_6.0</th>\n",
       "      <th>goal_5.0</th>\n",
       "      <th>career_c_1.0</th>\n",
       "      <th>career_c_3.0</th>\n",
       "      <th>career_c_4.0</th>\n",
       "      <th>career_c_5.0</th>\n",
       "      <th>career_c_7.0</th>\n",
       "      <th>career_c_10.0</th>\n",
       "      <th>career_c_11.0</th>\n",
       "      <th>subject_attractiveness_mean</th>\n",
       "      <th>subject_sincerity_mean</th>\n",
       "      <th>subject_intelligence_mean</th>\n",
       "      <th>subject_fun_mean</th>\n",
       "      <th>subject_ambition_mean</th>\n",
       "      <th>subject_shared_interest_mean</th>\n",
       "      <th>age_difference</th>\n",
       "      <th>attractiveness_difference</th>\n",
       "      <th>fun_difference</th>\n",
       "      <th>ambition_difference</th>\n",
       "      <th>shared_interest_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.093734</td>\n",
       "      <td>0.477190</td>\n",
       "      <td>0.405713</td>\n",
       "      <td>0.306851</td>\n",
       "      <td>0.129562</td>\n",
       "      <td>-0.215712</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.213498</td>\n",
       "      <td>-0.687122</td>\n",
       "      <td>-1.210467</td>\n",
       "      <td>-1.270431</td>\n",
       "      <td>-0.087847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.093734</td>\n",
       "      <td>0.477190</td>\n",
       "      <td>0.405713</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>-0.984028</td>\n",
       "      <td>-1.151207</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>0.113945</td>\n",
       "      <td>-1.261822</td>\n",
       "      <td>-1.210467</td>\n",
       "      <td>-0.630769</td>\n",
       "      <td>1.092457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>1.958469</td>\n",
       "      <td>1.053427</td>\n",
       "      <td>1.055676</td>\n",
       "      <td>-0.206682</td>\n",
       "      <td>0.129562</td>\n",
       "      <td>0.252036</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.540940</td>\n",
       "      <td>1.036978</td>\n",
       "      <td>0.020660</td>\n",
       "      <td>-1.270431</td>\n",
       "      <td>-0.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>1.445418</td>\n",
       "      <td>1.629664</td>\n",
       "      <td>1.705638</td>\n",
       "      <td>1.333917</td>\n",
       "      <td>0.686357</td>\n",
       "      <td>-0.215712</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.868383</td>\n",
       "      <td>-0.112422</td>\n",
       "      <td>-0.594903</td>\n",
       "      <td>-0.630769</td>\n",
       "      <td>-0.087847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.606785</td>\n",
       "      <td>-1.251521</td>\n",
       "      <td>-1.544174</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>-0.984028</td>\n",
       "      <td>0.252036</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.540940</td>\n",
       "      <td>1.036978</td>\n",
       "      <td>0.636223</td>\n",
       "      <td>0.648555</td>\n",
       "      <td>-1.268152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  pf_o_att  pf_o_sin  pf_o_int  dec_o    attr_o    sinc_o   intel_o  \\\n",
       "0   False        25        25        25  False -0.093734  0.477190  0.405713   \n",
       "1   False        25        20        15  False -0.093734  0.477190  0.405713   \n",
       "2   False        30        15        20   True  1.958469  1.053427  1.055676   \n",
       "3   False        40        20        20  False  1.445418  1.629664  1.705638   \n",
       "4   False        30        10        25  False -0.606785 -1.251521 -1.544174   \n",
       "\n",
       "      fun_o     amb_o    shar_o  imprelig  date  go_out  tvsports  exercise  \\\n",
       "0  0.306851  0.129562 -0.215712         7     4       2         6         7   \n",
       "1 -0.720215 -0.984028 -1.151207         7     4       2         6         7   \n",
       "2 -0.206682  0.129562  0.252036         7     4       2         6         7   \n",
       "3  1.333917  0.686357 -0.215712         7     4       2         6         7   \n",
       "4 -0.720215 -0.984028  0.252036         7     4       2         6         7   \n",
       "\n",
       "   dining  museums  art  hiking  gaming  reading  tv  theater  concerts  \\\n",
       "0       8        6    8       8       4        7   4        7         7   \n",
       "1       8        6    8       8       4        7   4        7         7   \n",
       "2       8        6    8       8       4        7   4        7         7   \n",
       "3       8        6    8       8       4        7   4        7         7   \n",
       "4       8        6    8       8       4        7   4        7         7   \n",
       "\n",
       "   music  attr1_1  sinc1_1  intel1_1  shar1_1  intel3_1  attr  sinc  intel  \\\n",
       "0      7       16       19        16       17         7     7     6      7   \n",
       "1      7       16       19        16       17         7     6     6      6   \n",
       "2      7       16       19        16       17         7     6     8      8   \n",
       "3      7       16       19        16       17         7     7     7      7   \n",
       "4      7       16       19        16       17         7     9     7      8   \n",
       "\n",
       "   fun  match_es  length  numdat_2  race_o_1.0  race_o_4.0  field_cd_2.0  \\\n",
       "0    7         3       1         3           0           0             0   \n",
       "1    5         3       1         3           0           0             0   \n",
       "2    8         3       1         3           0           0             0   \n",
       "3    8         3       1         3           0           0             0   \n",
       "4    8         3       1         3           0           0             0   \n",
       "\n",
       "   field_cd_3.0  field_cd_4.0  field_cd_6.0  field_cd_7.0  field_cd_9.0  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   field_cd_11.0  field_cd_15.0  race_2.0  race_3.0  race_6.0  goal_5.0  \\\n",
       "0              0              0         0         1         0         0   \n",
       "1              0              0         0         1         0         0   \n",
       "2              0              0         0         1         0         0   \n",
       "3              0              0         0         1         0         0   \n",
       "4              0              0         0         1         0         0   \n",
       "\n",
       "   career_c_1.0  career_c_3.0  career_c_4.0  career_c_5.0  career_c_7.0  \\\n",
       "0             0             0             0             1             0   \n",
       "1             0             0             0             1             0   \n",
       "2             0             0             0             1             0   \n",
       "3             0             0             0             1             0   \n",
       "4             0             0             0             1             0   \n",
       "\n",
       "   career_c_10.0  career_c_11.0  subject_attractiveness_mean  \\\n",
       "0              0              0                     6.357143   \n",
       "1              0              0                     6.357143   \n",
       "2              0              0                     6.357143   \n",
       "3              0              0                     6.357143   \n",
       "4              0              0                     6.357143   \n",
       "\n",
       "   subject_sincerity_mean  subject_intelligence_mean  subject_fun_mean  \\\n",
       "0                7.714286                   8.071429          6.357143   \n",
       "1                7.714286                   8.071429          6.357143   \n",
       "2                7.714286                   8.071429          6.357143   \n",
       "3                7.714286                   8.071429          6.357143   \n",
       "4                7.714286                   8.071429          6.357143   \n",
       "\n",
       "   subject_ambition_mean  subject_shared_interest_mean  age_difference  \\\n",
       "0               6.785714                      5.285714       -0.213498   \n",
       "1               6.785714                      5.285714        0.113945   \n",
       "2               6.785714                      5.285714       -0.540940   \n",
       "3               6.785714                      5.285714       -0.868383   \n",
       "4               6.785714                      5.285714       -0.540940   \n",
       "\n",
       "   attractiveness_difference  fun_difference  ambition_difference  \\\n",
       "0                  -0.687122       -1.210467            -1.270431   \n",
       "1                  -1.261822       -1.210467            -0.630769   \n",
       "2                   1.036978        0.020660            -1.270431   \n",
       "3                  -0.112422       -0.594903            -0.630769   \n",
       "4                   1.036978        0.636223             0.648555   \n",
       "\n",
       "   shared_interest_difference  \n",
       "0                   -0.087847  \n",
       "1                    1.092457  \n",
       "2                   -0.678000  \n",
       "3                   -0.087847  \n",
       "4                   -1.268152  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file, encoding= 'ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923cfea",
   "metadata": {},
   "source": [
    "### Modelling\n",
    "\n",
    "#### 1. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ac487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature and target variables\n",
    "features, target = df, df['dec_o']\n",
    "features.drop(['dec_o'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c959d",
   "metadata": {},
   "source": [
    "1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e85d66cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=0), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         &#x27;max_iter&#x27;: [10000], &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=0), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         &#x27;max_iter&#x27;: [10000], &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(random_state=0), n_jobs=-1,\n",
       "             param_grid={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         'max_iter': [10000], 'penalty': ['l2'],\n",
       "                         'solver': ['lbfgs']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 4.281332398719396, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'max_iter': [10000]\n",
    "}\n",
    "classifier_lr = LogisticRegression(random_state=__random_state)\n",
    "classifier_lr = GridSearchCV(\n",
    "    estimator=classifier_lr,\n",
    "    param_grid=parameters,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "classifier_lr.fit(features, target)\n",
    "classifier_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feb5009d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=4.281332398719396, max_iter=10000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=4.281332398719396, max_iter=10000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=4.281332398719396, max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_logistic_regression = LogisticRegression(\n",
    "    random_state=__random_state,\n",
    "    penalty=classifier_lr.best_params_['penalty'],\n",
    "    solver=classifier_lr.best_params_['solver'],\n",
    "    C=classifier_lr.best_params_['C'],\n",
    "    max_iter=classifier_lr.best_params_['max_iter']\n",
    ")\n",
    "clf_logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abb5a6",
   "metadata": {},
   "source": [
    "2. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0883558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.7s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.7s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.2s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.3s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.3s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.5s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.9s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.6s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.6s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.5s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.6s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.5s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.1s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.3s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.6s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.2s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.5s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.5s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.5s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.6s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.4s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.6s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.7s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.6s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.4s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.3s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.8s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.5s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.3s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.8s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.9s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   5.7s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   5.3s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   5.7s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.2s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   5.4s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   5.4s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   4.8s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   4.7s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.5s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.6s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   6.3s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   6.3s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   6.5s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   6.9s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   6.8s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   5.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   4.9s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  11.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   5.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   9.8s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   9.9s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   4.1s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   3.7s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   9.5s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   9.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(random_state=0), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [0.0001, 0.001, 0.01], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(random_state=0), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [0.0001, 0.001, 0.01], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(random_state=0), n_jobs=-1,\n",
       "             param_grid={'C': [1, 10, 100, 1000],\n",
       "                         'gamma': [0.0001, 0.001, 0.01], 'kernel': ['rbf']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [1e-4, 1e-3, 1e-2],\n",
    "    'C': [1, 10, 100, 1000]\n",
    "}\n",
    "classifier_sv = SVC(random_state=__random_state)\n",
    "classifier_sv = GridSearchCV(\n",
    "    estimator=classifier_sv,\n",
    "    param_grid=parameters,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "classifier_sv.fit(features, target)\n",
    "classifier_sv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9420d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.0001, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.0001, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, gamma=0.0001, random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc = SVC(\n",
    "    random_state=__random_state,\n",
    "    kernel=classifier_sv.best_params_['kernel'],\n",
    "    gamma=classifier_sv.best_params_['gamma'],\n",
    "    C=classifier_sv.best_params_['C']\n",
    ")\n",
    "clf_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ff551",
   "metadata": {},
   "source": [
    "3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee1862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.2s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.2s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.2s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.2s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.2s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.3s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.3s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.3s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.2s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.2s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.2s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.2s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.2s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.2s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.2s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.3s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.2s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.2s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.6s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.6s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.6s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.6s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.7s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.6s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.7s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.6s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.6s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.6s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.7s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.7s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.7s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.6s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.6s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.6s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.7s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.7s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.7s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.7s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.7s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.7s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.6s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.7s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.7s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.5s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.6s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.5s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;minkowski&#x27;, &#x27;euclidean&#x27;, &#x27;manhattan&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 11, 19, 29],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;minkowski&#x27;, &#x27;euclidean&#x27;, &#x27;manhattan&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 11, 19, 29],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'metric': ['minkowski', 'euclidean', 'manhattan'],\n",
       "                         'n_neighbors': [5, 11, 19, 29],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 29, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_neighbors': [5, 11, 19, 29],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "}\n",
    "classifier_kn = KNeighborsClassifier()\n",
    "classifier_kn = GridSearchCV(\n",
    "    estimator=classifier_kn,\n",
    "    param_grid=parameters,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "classifier_kn.fit(features, target)\n",
    "classifier_kn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ca18a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=29)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=29)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='manhattan', n_neighbors=29)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier(\n",
    "    n_neighbors=classifier_kn.best_params_['n_neighbors'],\n",
    "    weights=classifier_kn.best_params_['weights'],\n",
    "    metric=classifier_kn.best_params_['metric']\n",
    ")\n",
    "clf_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803e1ca",
   "metadata": {},
   "source": [
    "#### 2. Ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce0a76d",
   "metadata": {},
   "source": [
    "1. Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa7bff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05],\n",
       "                         &#x27;loss&#x27;: [&#x27;deviance&#x27;, &#x27;exponential&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05],\n",
       "                         &#x27;loss&#x27;: [&#x27;deviance&#x27;, &#x27;exponential&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.05],\n",
       "                         'loss': ['deviance', 'exponential'],\n",
       "                         'max_depth': [3, 4, 5],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'loss': 'exponential',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'learning_rate': [0.05],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "classifier_gb = GradientBoostingClassifier(random_state=__random_state)\n",
    "classifier_gb = GridSearchCV(\n",
    "    estimator=classifier_gb,\n",
    "    param_grid=parameters,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "classifier_gb.fit(features, target)\n",
    "classifier_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd3b526f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.05, loss=&#x27;exponential&#x27;, max_depth=4,\n",
       "                           max_features=&#x27;sqrt&#x27;, n_estimators=300,\n",
       "                           random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.05, loss=&#x27;exponential&#x27;, max_depth=4,\n",
       "                           max_features=&#x27;sqrt&#x27;, n_estimators=300,\n",
       "                           random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.05, loss='exponential', max_depth=4,\n",
       "                           max_features='sqrt', n_estimators=300,\n",
       "                           random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gb = GradientBoostingClassifier(\n",
    "    random_state=__random_state,\n",
    "    loss=classifier_gb.best_params_['loss'],\n",
    "    learning_rate=classifier_gb.best_params_['learning_rate'],\n",
    "    n_estimators=classifier_gb.best_params_['n_estimators'],\n",
    "    max_depth=classifier_gb.best_params_['max_depth'],\n",
    "    max_features=classifier_gb.best_params_['max_features']\n",
    ")\n",
    "clf_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68621907",
   "metadata": {},
   "source": [
    "2. Voting Classifier\n",
    "\n",
    "Let's combine all classifiers and train a voting and stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lr', clf_logistic_regression), # logistic regression\n",
    "    ('sv', clf_svc), # svc\n",
    "    ('kn', clf_knn), # knn\n",
    "    ('gb', clf_gb) # gradient boosting\n",
    "]\n",
    "\n",
    "# voting classifier\n",
    "clf_voting = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# stacking classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad0aea",
   "metadata": {},
   "source": [
    "#### 1. Basic checking of data\n",
    "\n",
    "Generally, don't tend to care about data types until we get an error or some unexpected results. However, it's better to check that data types are correctly loaded before you start your analysis. You can read more about data types in pandas [here](https://pbpython.com/pandas_dtypes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58391e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.memory_usage().sum() # memory usage in bytes\n",
    "df.dtypes.to_frame(name='data types').T # T will represent the transpose of the resulting dataframe, better for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c1276",
   "metadata": {},
   "source": [
    "##### Comment\n",
    "- Seems like all the features were loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd252c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Categorical Features\")\n",
    "df.describe(include='O').T \n",
    "\n",
    "#display(\"Numeric Features\")\n",
    "#df.describe(include='number').T "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3cf6c",
   "metadata": {},
   "source": [
    "Some features have wrong data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_str_to_int = ['mn_sat', 'tuition', 'zipcode', 'income'] # features which needs to be converted to int\n",
    "for col in cols_str_to_int:\n",
    "    df[col] = df[col].fillna('0').str.replace(\",\",\"\").astype(np.float).astype(int)\n",
    "    # df[col] = pd.to_numeric(df[col].str.replace(\",\",\"\"), errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36c97aa",
   "metadata": {},
   "source": [
    "Verify that data type is changed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f249b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Categorical Features\")\n",
    "df.describe(include='O').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f108efcf",
   "metadata": {},
   "source": [
    "#### 2. Columns renaming & dropping irrelevant columns\n",
    "\n",
    "It's better to rename columns (without white characters and preferably in _lower case_), so it's easier to deal with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f304651",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_frame().reset_index().T.head(1) # showing columns in a more visual way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13b45e",
   "metadata": {},
   "source": [
    "##### Comment\n",
    "\n",
    "- No need to change the column names since all are lower case and without any white characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb593b2",
   "metadata": {},
   "source": [
    "Based on our domain knowledge, we have identified relevant features and their associated datatypes. Let's drop the irrelevant features and update the data types again (just for clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features = [\n",
    "    ['iid', 'int16'], ['gender', 'bool'],\n",
    "    ['wave', 'int16'], ['position', 'int16'],\n",
    "    ['order', 'int16'], ['pid', 'int16'],\n",
    "    ['age_o', 'int16'], ['race_o', 'category'],\n",
    "    ['pf_o_att', 'int16'], ['pf_o_sin', 'int16'],\n",
    "    ['pf_o_int', 'int16'], ['pf_o_fun', 'int16'],\n",
    "    ['pf_o_amb', 'int16'], ['pf_o_sha', 'int16'],\n",
    "    ['dec_o', 'bool'], ['attr_o', 'int16'], ['sinc_o', 'int16'], \n",
    "    ['intel_o', 'int16'], ['fun_o', 'int16'], ['amb_o', 'int16'], \n",
    "    ['shar_o', 'int16'], ['like_o', 'int16'],\n",
    "    ['prob_o', 'int16'], ['met_o', 'bool'], ['age', 'int16'], ['field_cd', 'category'], ['race', 'category'],\n",
    "    ['imprace', 'int16'], ['imprelig', 'int16'], ['goal', 'category'], ['date', 'int16'],\n",
    "    ['go_out', 'int16'], ['career_c', 'category'], ['sports', 'int16'], ['tvsports', 'int16'], ['exercise', 'int16'],\n",
    "    ['dining', 'int16'], ['museums', 'int16'], ['art', 'int16'], ['hiking', 'int16'],\n",
    "    ['gaming', 'int16'], ['clubbing', 'int16'], ['reading', 'int16'], ['tv', 'int16'],\n",
    "    ['theater', 'int16'], ['movies', 'int16'], ['concerts', 'int16'], ['music', 'int16'],\n",
    "    ['shopping', 'int16'], ['yoga', 'int16'], ['exphappy', 'int16'], ['expnum', 'int16'],\n",
    "    ['attr1_1', 'int16'], ['sinc1_1', 'int16'], ['intel1_1', 'int16'], ['fun1_1', 'int16'],\n",
    "    ['amb1_1', 'int16'], ['shar1_1', 'int16'], ['attr3_1', 'int16'], ['sinc3_1', 'int16'],\n",
    "    ['fun3_1', 'int16'], ['intel3_1', 'int16'], ['amb3_1', 'int16'], ['dec', 'bool'],\n",
    "    ['attr', 'int16'], ['sinc', 'int16'], ['intel', 'int16'], ['fun', 'int16'],\n",
    "    ['amb', 'int16'], ['shar', 'int16'], ['like', 'int16'], ['prob', 'int16'],\n",
    "    ['met', 'int16'], ['match_es', 'int16'], ['satis_2', 'int16'], ['length', 'int16'],\n",
    "    ['numdat_2', 'int16']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[feature[0] for feature in relevant_features]]\n",
    "df.shape\n",
    "df.memory_usage().sum() # memory usage in bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f8f13",
   "metadata": {},
   "source": [
    "Let's update the data types for the relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({feature: datatype if all(df[feature].notna().values) else 'float32' if datatype == 'int16' else datatype for (feature, datatype) in relevant_features})\n",
    "df.dtypes.to_frame(name='data types').T # T will represent the transpose of the resulting dataframe, better for visualization\n",
    "df.shape\n",
    "df.memory_usage().sum() # memory usage in bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13b45e",
   "metadata": {},
   "source": [
    "##### Comment\n",
    "\n",
    "- After dropping irrelevant data and updating the datatypes, the dataframe size almost reduced by 82% the original size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bba4bd",
   "metadata": {},
   "source": [
    "#### 3. Split your dataset into train and test datasets\n",
    "\n",
    "We will split our dataset into two parts: `train` & `test` datasets. We will do all the processing on the `train` dataset. `test` dataset will remain unknown to us. And we will use it only for testing analysis. This is to simulate the real world scenario in which we don't know the data which would be run on our model (after deploying)\n",
    "\n",
    "However, there may be some issues with the `test` dataset (especially if our original dataset is bit imbalance):\n",
    "\n",
    "1. What if few categories are missed in `test` dataset ? we won't have any hot encoding for those categories.\n",
    "\n",
    "> One possible solution is to hot encode the new unseen categories as zero (or some default category)\n",
    "\n",
    "> Another possible solution is to do stratified sampling (in case of imbalance data), so you have data for all the categories in both `train` and `test` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dec.replace(0, 'No').replace(1, 'Yes').value_counts().plot(kind = 'bar')\n",
    "dec_options = {False: \"No\", True: \"Yes\"}\n",
    "count_ss = df.dec.replace(dec_options).value_counts() # final decision. 1 = Yes, 0 = No\n",
    "ax = sns.barplot(x = count_ss.index, y = count_ss.values)\n",
    "_ = ax.set(xlabel='decision', ylabel='count')\n",
    "_ = ax.bar_label(ax.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca5b9c",
   "metadata": {},
   "source": [
    "Let's plot the distributions of subject attribute ratings from their partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16,10))\n",
    "_ = plt.tight_layout(pad=5.0)\n",
    "\n",
    "bins = np.arange(0, 10, 0.5).tolist()\n",
    "ylabel = \"No. of subjects\"\n",
    "\n",
    "cols = ['attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o']\n",
    "xlabels = ['Attractiveness rating', 'Sincerity rating', 'Intelligence rating', 'Fun rating', 'Ambition rating', 'Shared interest rating']\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    _ = plt.subplot(2,3, i + 1)\n",
    "    xlabel = xlabels[i]\n",
    "    plot_distribution(\n",
    "        data=df[col],\n",
    "        bins=bins,\n",
    "        title=\"Subject's {}\".format(xlabel),\n",
    "        xlabel=\"{}\".format(xlabel),\n",
    "        ylabel=ylabel\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbceec",
   "metadata": {},
   "source": [
    "We have a sightly imbalance data (for `decision` parameter). We will be doing a stratified split for equal proprtion in `train` and `test` datasets. You can check the official doc for `train_test_split` [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0567809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the random state too, so you we can reproduce the results later as well\n",
    "__random_state = 0\n",
    "\n",
    "# let's do a 85% | 15% split\n",
    "train_df, test_df = train_test_split(df, test_size=0.15, shuffle=True, random_state=__random_state, stratify=df['dec'])\n",
    "\n",
    "# reset the index for train and test\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59eec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train_df.dec.replace(dec_options).value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = test_df.dec.replace(dec_options).value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66430aec",
   "metadata": {},
   "source": [
    "Both `train` and `test` datasets have the same ratio of values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b69f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.describe(include='all').T # check train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcfcc29",
   "metadata": {},
   "source": [
    "Save the `train` & `test` dataset as a `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa848134",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = join(data_dir, \"train.csv\")\n",
    "dataframe_to_csv(train_df, train_file_path)\n",
    "\n",
    "test_file_path = join(data_dir, \"test.csv\")\n",
    "dataframe_to_csv(test_df, test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd778c23",
   "metadata": {},
   "source": [
    "#### 4. Check for missing data\n",
    "\n",
    "We need to check for missing data and imputate or remove it. It is really important to deal with all the missing data to get better EDA and less incorrect results during model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a basic first step is to check if any data is missing in predicted value\n",
    "# because if some labels are not there in y_train, there isn't any point to include those rows\n",
    "\n",
    "train_df['dec'].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2df2a",
   "metadata": {},
   "source": [
    "So basically we are good here. Now let's see how much missing values we have for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c0d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "((train_df.isna().sum()/len(train_df)) * 100).to_frame(name='missing %').sort_values(by=['missing %'], ascending=False).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e240c",
   "metadata": {},
   "source": [
    "Okay! so we have lots of columns with missing values (_as also already shown in EDA too_). Let's see what are the typical ways to deal with them\n",
    "\n",
    "There are multiple ways to compute the missing values. Although most of them are `distance based` and only work on _numeric_ features. Missing values are computed on training data only otherwise it can cause _Data Leakage_ (accidentally share the information between the `test` and `train` datasets) as well. List below are the typical ways we use to deal with missing values:\n",
    "\n",
    "1. Check manually what values are missing and correct them. We can check if there is a pattern to the missing values, think about the possible reasons why it happened in the first place\n",
    "\n",
    "2. Also, it is know practice to drop the columns if they have more than ~50% of the missing values\n",
    "\n",
    "3. Deleting rows with missing values - Deleting rows (if we have enough data) or column (if column is not important intutive idea from domain knowledge)\n",
    "\n",
    "4. Impute missing values for continuous variable - mean/median - without causing _data leakage_\n",
    "\n",
    "5. Impute missing values for categorical variable - mode ('most_frequent' or 'constant' strategy)\n",
    "\n",
    "6. Other Imputation Methods - interpolation (provide missing term using nearby trends, newton forward/backward formula, for multivariate - nearest neighbour interpolation, gaussian, polynomial (good for time series interpolation))\n",
    "\n",
    "7. Using Algorithms that support missing values (k-NN - based on k, get the closest rows using euclidean distance and take the average of there missing value column values)\n",
    "\n",
    "> Note: Imputation: Replace missing datas with statistical values. sklearn has a [`Imputation` module (sklearn.impute)](https://scikit-learn.org/stable/modules/impute.html#impute) which is quite helpful here.\n",
    "\n",
    "#### How to impute the missing data ? What do we need ?\n",
    "\n",
    "- A generalized model for missing values so that if values are missing in test data the model will not break\n",
    "- Although the mordern tree based algorithms manages the missing values by default using techniques such as `fragments` and `surrogate splits` so while using these algos we do not need to worry about missing values\n",
    "- We can make a gernalized imputation model which can deal with all the unexpected missing values if required\n",
    "\n",
    "---\n",
    "\n",
    "#### Some of the imputers being used from [_sklearn.impute_](https://scikit-learn.org/stable/modules/impute.html#impute) module\n",
    "\n",
    "##### [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer)\n",
    "\n",
    "- Replace `NaN` (`np.nan`) by the `mean`, `median`, `most_frequent` or `constant`\n",
    "\n",
    "\n",
    "##### [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer)\n",
    "\n",
    "- Replace your missing values by closest ones\n",
    "- Imputation for completing missing values using k-Nearest Neighbors\n",
    "- Each sample’s missing values are imputed using the _mean_ value from `n_neighbors` nearest neighbors found in the training set. Two samples are close if the features that neither is missing are close\n",
    "\n",
    "##### [MissingIndicator](https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html#sklearn.impute.MissingIndicator)\n",
    "\n",
    "- Position of missing values by a `boolean` mask\n",
    "\n",
    "##### [IterativeImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html)\n",
    "\n",
    "- Multivariate imputer that estimates each feature from all the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold for missing value - remove all columns which has greater than 50% of missing values\n",
    "__missing_threshold = float(50)\n",
    "\n",
    "missing_df = ((train_df.isna().sum()/len(train_df)) * 100).to_frame(name='missing').sort_values(by=['missing'], ascending=False).query(\"missing > {}\".format(__missing_threshold))\n",
    "missing_cols = missing_df.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputate missing values\n",
    "def iterative_imputate_missing_features(data, random_state = 0, relevant_features=None):\n",
    "    \"\"\"\n",
    "    Method to imputate missing values using IterativeImputer\n",
    "    \"\"\"\n",
    "    imputer = IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        sample_posterior=True, # sample from gaussian predictive posterior\n",
    "        n_nearest_features=5,\n",
    "        min_value=0,\n",
    "        max_value=100,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    imputer.fit(data)\n",
    "    data_imputed = np.around(imputer.transform(data))\n",
    "    data = pd.DataFrame(data_imputed, columns=data.columns)\n",
    "    if relevant_features:\n",
    "        data = data.astype({feature: datatype if all(data[feature].notna().values) else 'float32' if datatype == 'int16' else datatype for (feature, datatype) in relevant_features})\n",
    "    return data, imputer\n",
    "\n",
    "def imputate_missing_features(data, missing_threshold = 50):\n",
    "    \"\"\"\n",
    "    Method to imputate missing values and return a imputate model\n",
    "    \"\"\"\n",
    "\n",
    "    # threshold for missing value - remove all columns which has greater than 50% of missing values\n",
    "    __missing_threshold = missing_threshold\n",
    "\n",
    "    missing_df = ((data.isna().sum()/len(data)) * 100).to_frame(name='missing').sort_values(by=['missing'], ascending=False).query(\"missing > {}\".format(__missing_threshold))\n",
    "    missing_cols = missing_df.index.to_list()\n",
    "\n",
    "    cols_to_use = list(set(data.columns.to_list()) - set(missing_cols))\n",
    "    cols_to_use = [x for x in cols_to_use if x != 'dec']\n",
    "    \n",
    "    #X, y = data[cols_to_use], data['dec']\n",
    "    X, y = data, data['dec']\n",
    "    X.drop(['dec'], axis=1, inplace=True)\n",
    "\n",
    "    num_features = make_column_selector(dtype_include=np.number) # get all numeric data\n",
    "    cat_features = make_column_selector(dtype_exclude=np.number)\n",
    "\n",
    "    imputate_pipeline = make_column_transformer(\n",
    "        (SimpleImputer(strategy='mean'), num_features),\n",
    "        (MissingIndicator(missing_values=np.nan, features=\"all\", error_on_new=False), num_features),\n",
    "\n",
    "        remainder=\"drop\", # drop the remaining columns\n",
    "        n_jobs=-1, # run jobs using all available processors (for speedup computation)\n",
    "    )\n",
    "\n",
    "    num_pipe = make_pipeline(\n",
    "        KNNImputer(n_neighbors=5, add_indicator=True),    # stack MissingIndicator on the output\n",
    "        #imputate_pipeline,\n",
    "        StandardScaler()\n",
    "    )\n",
    "\n",
    "    cat_pipe = make_pipeline(\n",
    "        SimpleImputer(strategy = 'most_frequent'),\n",
    "        OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    )\n",
    "\n",
    "    col_trans = make_column_transformer(\n",
    "        (num_pipe, num_features),\n",
    "        (cat_pipe, cat_features)\n",
    "    )\n",
    "\n",
    "    col_trans.fit(X)\n",
    "\n",
    "    return X, cols_to_use, col_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, col_trans = iterative_imputate_missing_features(train_df, __random_state, relevant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape\n",
    "col_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2529dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, cols_to_use, col_trans = imputate_missing_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d440f",
   "metadata": {},
   "source": [
    "Save the imputated model as pickle (`.pkl`) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(col_trans, join(model_dir, \"col_trans.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835479e6",
   "metadata": {},
   "source": [
    "Imputate the `train` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef46337",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().any() # check missing values now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95db9c2",
   "metadata": {},
   "source": [
    "#### 5. Check for outliers\n",
    "\n",
    "In order to check outliers in your dataset, there are various methods worth looking into:\n",
    "\n",
    "1. _Box plots_\n",
    "2. _Z-score test (normal distribution assumption)_\n",
    "3. _Model based (One class SVM, density based algorithams, etc)_\n",
    "\n",
    "Some useful resources:\n",
    "\n",
    "- [Novelty and Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)\n",
    "- [Ways to Detect and Remove the Outliers](https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba)\n",
    "\n",
    "> For our use case, we will be checking outliers with _box plots_ and _density based algoritham_ (`DBSCAN`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c1aef7",
   "metadata": {},
   "source": [
    "##### Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box_plots(df, cols):\n",
    "    \"\"\"\n",
    "    Draw Box Plot & Histogram for each column\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        fig, axes= plt.subplots(1,2, gridspec_kw={'width_ratios': [1, 4]}, figsize=(9,5))\n",
    "        _ = df.boxplot(column=col,ax=axes[0]);\n",
    "        _ = df.hist(column=col, ax=axes[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all numeric columns\n",
    "train_numeric = train_df.select_dtypes(include=\"number\")\n",
    "draw_box_plots(train_df, train_numeric.columns)\n",
    "# train_numeric.shape\n",
    "# train_numeric.head()\n",
    "# total_num_cols = len(train_numeric.columns)\n",
    "# for col in train_numeric.columns:\n",
    "#     fig, axes= plt.subplots(1,2, gridspec_kw={'width_ratios': [1, 4]}, figsize=(9,5))\n",
    "#     _ = train_df.boxplot(column=col,ax=axes[0]);\n",
    "#     _ = train_df.hist(column=col, ax=axes[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2501dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df, col, mode=1, times_std=3):\n",
    "    \"\"\"\n",
    "    Basic way to remove outliers\n",
    "\n",
    "    mode = 1 (via mean and std) \n",
    "    mode = 2 (via IQR)\n",
    "    \"\"\"\n",
    "    if mode == 1: # with mean and std\n",
    "        upper_limit = df[col].mean() + times_std * df[col].std()\n",
    "        lower_limit = df[col].mean() - times_std * df[col].std()\n",
    "        df[col] = np.where(\n",
    "            df[col] > upper_limit,\n",
    "            upper_limit,\n",
    "            np.where(\n",
    "                df[col] < lower_limit,\n",
    "                lower_limit,\n",
    "                df[col]\n",
    "            )\n",
    "        )\n",
    "    elif mode == 2:\n",
    "\n",
    "        p_25, p_75 = df[col].quantile(0.25), df[col].quantile(0.75)\n",
    "        iqr = p_75 - p_25\n",
    "        upper_limit = p_75 + 1.5 * iqr\n",
    "        lower_limit = p_25 - 1.5 * iqr\n",
    "\n",
    "        df[col] = np.where(\n",
    "            df[col] > upper_limit,\n",
    "            upper_limit,\n",
    "            np.where(\n",
    "                df[col] < lower_limit,\n",
    "                lower_limit,\n",
    "                df[col]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        print(\"Unsupported mode\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974731c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = remove_outlier(train_df, train_numeric.columns, mode=2)\n",
    "#draw_box_plots(train_df, train_numeric.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380382e3",
   "metadata": {},
   "source": [
    "##### Comment\n",
    "\n",
    "- Removed all the outliers from the data\n",
    "\n",
    "---\n",
    "\n",
    "#### Clustering Algorithm\n",
    "\n",
    "##### [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)\n",
    "\n",
    "- DBSCAN - Density-Based Spatial Clustering of Applications with Noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c282b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the attribute using domain knowledge\n",
    "# outlier_detection = DBSCAN(min_samples = 4, eps = 0.5)\n",
    "\n",
    "# make clusters\n",
    "# normalized_df=(train_numeric - train_numeric.min()) / (train_numeric.max() - train_numeric.min())\n",
    "# clusters = outlier_detection.fit_predict(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785eaf3",
   "metadata": {},
   "source": [
    "#### 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a9d9ee",
   "metadata": {},
   "source": [
    "Encode nominal features using one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a4b6338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nominal = train_df.dtypes[train_df.dtypes == 'category'].index.values\n",
    "train_df = pd.get_dummies(train_df, prefix=features_nominal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea132989",
   "metadata": {},
   "source": [
    "Calculate the average attribute ratings for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3a1e259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df.copy()\n",
    "\n",
    "subject_attractiveness_mean = data[['iid', 'attr_o']].groupby(['iid']).mean()['attr_o']\n",
    "subject_sincerity_mean = data[['iid', 'sinc_o']].groupby(['iid']).mean()['sinc_o']\n",
    "subject_intelligence_mean = data[['iid', 'intel_o']].groupby(['iid']).mean()['intel_o']\n",
    "subject_fun_mean = data[['iid', 'fun_o']].groupby(['iid']).mean()['fun_o']\n",
    "subject_ambition_mean = data[['iid', 'amb_o']].groupby(['iid']).mean()['amb_o']\n",
    "subject_shared_interest_mean = data[['iid', 'shar_o']].groupby(['iid']).mean()['shar_o']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a0faa",
   "metadata": {},
   "source": [
    "Insert average attribute ratings into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "60f17899",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(\n",
    "    right=subject_attractiveness_mean,\n",
    "    how='inner',\n",
    "    on='iid'\n",
    ").rename(columns={\n",
    "    'attr_o_x': 'attr_o',\n",
    "    'attr_o_y': 'subject_attractiveness_mean'\n",
    "})\n",
    "data = data.merge(\n",
    "    right=subject_sincerity_mean,\n",
    "    how='inner',\n",
    "    on='iid'\n",
    ").rename(columns={\n",
    "    'sinc_o_x': 'sinc_o',\n",
    "    'sinc_o_y': 'subject_sincerity_mean'\n",
    "})\n",
    "data = data.merge(\n",
    "    right=subject_intelligence_mean,\n",
    "    how='inner',\n",
    "    on='iid'\n",
    ").rename(columns={\n",
    "    'intel_o_x': 'intel_o',\n",
    "    'intel_o_y': 'subject_intelligence_mean'\n",
    "})\n",
    "data = data.merge(\n",
    "    right=subject_fun_mean,\n",
    "    how='inner',\n",
    "    on='iid'\n",
    ").rename(columns={\n",
    "    'fun_o_x': 'fun_o',\n",
    "    'fun_o_y': 'subject_fun_mean'\n",
    "})\n",
    "data = data.merge(\n",
    "    right=subject_ambition_mean,\n",
    "    how='inner',\n",
    "    on='iid'\n",
    ").rename(columns={\n",
    "    'amb_o_x': 'amb_o',\n",
    "    'amb_o_y': 'subject_ambition_mean'\n",
    "})\n",
    "data = data.merge(\n",
    "    right=subject_shared_interest_mean,\n",
    "    how='inner',\n",
    "    on='iid'\n",
    ").rename(columns={\n",
    "    'shar_o_x': 'shar_o',\n",
    "    'shar_o_y': 'subject_shared_interest_mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5dd4d",
   "metadata": {},
   "source": [
    "Calculate difference between subject and partner's ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e4e92bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_difference'] = abs(data['age'] - data['age_o'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08104db",
   "metadata": {},
   "source": [
    "Calculate difference between subject's attribute ratings and partner's attributes ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "07d13bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['attractiveness_difference'] = abs(data['attr'] - data['attr_o'])\n",
    "data['sincerity_difference'] = abs(data['sinc'] - data['sinc_o'])\n",
    "data['intelligence_difference'] = abs(data['intel'] - data['intel_o'])\n",
    "data['fun_difference'] = abs(data['fun'] - data['fun_o'])\n",
    "data['ambition_difference'] = abs(data['amb'] - data['amb_o'])\n",
    "data['shared_interest_difference'] = abs(data['shar'] - data['shar_o'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d7c11",
   "metadata": {},
   "source": [
    "Scale normal features to zero mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9a8fb7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_normal = [\n",
    "    'attr_o',\n",
    "    'sinc_o',\n",
    "    'intel_o',\n",
    "    'fun_o',\n",
    "    'amb_o',\n",
    "    'shar_o',\n",
    "    'age_difference',\n",
    "    'attractiveness_difference',\n",
    "    'sincerity_difference',\n",
    "    'intelligence_difference',\n",
    "    'fun_difference',\n",
    "    'ambition_difference',\n",
    "    'shared_interest_difference'\n",
    "]\n",
    "\n",
    "data[features_normal] = data[features_normal].apply(lambda x: preprocessing.scale(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0341f9",
   "metadata": {},
   "source": [
    "Drop some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "971328f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant features which contain no information about the target variable\n",
    "features_no_information = [\n",
    "    'iid',\n",
    "    'pid',\n",
    "    'wave',\n",
    "    'position',\n",
    "    'order'\n",
    "]\n",
    "# Drop features that are known in the future\n",
    "features_future_information = [\n",
    "    'dec',\n",
    "    'dec_o',\n",
    "    'like',\n",
    "    'prob',\n",
    "    'like_o',\n",
    "    'prob_o'\n",
    "]\n",
    "\n",
    "# Drop features that have low variance\n",
    "feature_variances = data.std().sort_values(ascending=True)\n",
    "features_low_variance = feature_variances[feature_variances < 0.1].index.values.tolist()\n",
    "\n",
    "# Drop features that have weak correlation with target variable\n",
    "correlations = data.corr().abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "correlations = correlations[correlations != 1]\n",
    "partner_decision_correlations = correlations.loc['dec_o']\n",
    "features_weak_correlation = partner_decision_correlations[partner_decision_correlations < 0.1].axes[0].to_list()\n",
    "features_weak_correlation = list(set(features_weak_correlation) - set(features_future_information) - set(features_no_information))\n",
    "\n",
    "# Drop features that were used in interaction variables\n",
    "features_interaction = [\n",
    "    'age',\n",
    "    'age_o',\n",
    "]\n",
    "\n",
    "features_remove = features_no_information + features_future_information + features_low_variance + features_weak_correlation + features_interaction\n",
    "data.drop(columns=features_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f5340eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>match_es</th>\n",
       "      <th>length</th>\n",
       "      <th>numdat_2</th>\n",
       "      <th>race_o_1.0</th>\n",
       "      <th>race_o_4.0</th>\n",
       "      <th>field_cd_2.0</th>\n",
       "      <th>field_cd_3.0</th>\n",
       "      <th>field_cd_4.0</th>\n",
       "      <th>field_cd_6.0</th>\n",
       "      <th>field_cd_7.0</th>\n",
       "      <th>field_cd_9.0</th>\n",
       "      <th>field_cd_11.0</th>\n",
       "      <th>field_cd_15.0</th>\n",
       "      <th>race_2.0</th>\n",
       "      <th>race_3.0</th>\n",
       "      <th>race_6.0</th>\n",
       "      <th>goal_5.0</th>\n",
       "      <th>career_c_1.0</th>\n",
       "      <th>career_c_3.0</th>\n",
       "      <th>career_c_4.0</th>\n",
       "      <th>career_c_5.0</th>\n",
       "      <th>career_c_7.0</th>\n",
       "      <th>career_c_10.0</th>\n",
       "      <th>career_c_11.0</th>\n",
       "      <th>subject_attractiveness_mean</th>\n",
       "      <th>subject_sincerity_mean</th>\n",
       "      <th>subject_intelligence_mean</th>\n",
       "      <th>subject_fun_mean</th>\n",
       "      <th>subject_ambition_mean</th>\n",
       "      <th>subject_shared_interest_mean</th>\n",
       "      <th>age_difference</th>\n",
       "      <th>attractiveness_difference</th>\n",
       "      <th>fun_difference</th>\n",
       "      <th>ambition_difference</th>\n",
       "      <th>shared_interest_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.093734</td>\n",
       "      <td>0.477190</td>\n",
       "      <td>0.405713</td>\n",
       "      <td>0.306851</td>\n",
       "      <td>0.129562</td>\n",
       "      <td>-0.215712</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.213498</td>\n",
       "      <td>-0.687122</td>\n",
       "      <td>-1.210467</td>\n",
       "      <td>-1.270431</td>\n",
       "      <td>-0.087847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.093734</td>\n",
       "      <td>0.477190</td>\n",
       "      <td>0.405713</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>-0.984028</td>\n",
       "      <td>-1.151207</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>0.113945</td>\n",
       "      <td>-1.261822</td>\n",
       "      <td>-1.210467</td>\n",
       "      <td>-0.630769</td>\n",
       "      <td>1.092457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1.958469</td>\n",
       "      <td>1.053427</td>\n",
       "      <td>1.055676</td>\n",
       "      <td>-0.206682</td>\n",
       "      <td>0.129562</td>\n",
       "      <td>0.252036</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.540940</td>\n",
       "      <td>1.036978</td>\n",
       "      <td>0.020660</td>\n",
       "      <td>-1.270431</td>\n",
       "      <td>-0.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1.445418</td>\n",
       "      <td>1.629664</td>\n",
       "      <td>1.705638</td>\n",
       "      <td>1.333917</td>\n",
       "      <td>0.686357</td>\n",
       "      <td>-0.215712</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.868383</td>\n",
       "      <td>-0.112422</td>\n",
       "      <td>-0.594903</td>\n",
       "      <td>-0.630769</td>\n",
       "      <td>-0.087847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.606785</td>\n",
       "      <td>-1.251521</td>\n",
       "      <td>-1.544174</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>-0.984028</td>\n",
       "      <td>0.252036</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.540940</td>\n",
       "      <td>1.036978</td>\n",
       "      <td>0.636223</td>\n",
       "      <td>0.648555</td>\n",
       "      <td>-1.268152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  pf_o_att  pf_o_sin  pf_o_int    attr_o    sinc_o   intel_o  \\\n",
       "0   False        25        25        25 -0.093734  0.477190  0.405713   \n",
       "1   False        25        20        15 -0.093734  0.477190  0.405713   \n",
       "2   False        30        15        20  1.958469  1.053427  1.055676   \n",
       "3   False        40        20        20  1.445418  1.629664  1.705638   \n",
       "4   False        30        10        25 -0.606785 -1.251521 -1.544174   \n",
       "\n",
       "      fun_o     amb_o    shar_o  imprelig  date  go_out  tvsports  exercise  \\\n",
       "0  0.306851  0.129562 -0.215712         7     4       2         6         7   \n",
       "1 -0.720215 -0.984028 -1.151207         7     4       2         6         7   \n",
       "2 -0.206682  0.129562  0.252036         7     4       2         6         7   \n",
       "3  1.333917  0.686357 -0.215712         7     4       2         6         7   \n",
       "4 -0.720215 -0.984028  0.252036         7     4       2         6         7   \n",
       "\n",
       "   dining  museums  art  hiking  gaming  reading  tv  theater  concerts  \\\n",
       "0       8        6    8       8       4        7   4        7         7   \n",
       "1       8        6    8       8       4        7   4        7         7   \n",
       "2       8        6    8       8       4        7   4        7         7   \n",
       "3       8        6    8       8       4        7   4        7         7   \n",
       "4       8        6    8       8       4        7   4        7         7   \n",
       "\n",
       "   music  attr1_1  sinc1_1  intel1_1  shar1_1  intel3_1  attr  sinc  intel  \\\n",
       "0      7       16       19        16       17         7     7     6      7   \n",
       "1      7       16       19        16       17         7     6     6      6   \n",
       "2      7       16       19        16       17         7     6     8      8   \n",
       "3      7       16       19        16       17         7     7     7      7   \n",
       "4      7       16       19        16       17         7     9     7      8   \n",
       "\n",
       "   fun  match_es  length  numdat_2  race_o_1.0  race_o_4.0  field_cd_2.0  \\\n",
       "0    7         3       1         3           0           0             0   \n",
       "1    5         3       1         3           0           0             0   \n",
       "2    8         3       1         3           0           0             0   \n",
       "3    8         3       1         3           0           0             0   \n",
       "4    8         3       1         3           0           0             0   \n",
       "\n",
       "   field_cd_3.0  field_cd_4.0  field_cd_6.0  field_cd_7.0  field_cd_9.0  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   field_cd_11.0  field_cd_15.0  race_2.0  race_3.0  race_6.0  goal_5.0  \\\n",
       "0              0              0         0         1         0         0   \n",
       "1              0              0         0         1         0         0   \n",
       "2              0              0         0         1         0         0   \n",
       "3              0              0         0         1         0         0   \n",
       "4              0              0         0         1         0         0   \n",
       "\n",
       "   career_c_1.0  career_c_3.0  career_c_4.0  career_c_5.0  career_c_7.0  \\\n",
       "0             0             0             0             1             0   \n",
       "1             0             0             0             1             0   \n",
       "2             0             0             0             1             0   \n",
       "3             0             0             0             1             0   \n",
       "4             0             0             0             1             0   \n",
       "\n",
       "   career_c_10.0  career_c_11.0  subject_attractiveness_mean  \\\n",
       "0              0              0                     6.357143   \n",
       "1              0              0                     6.357143   \n",
       "2              0              0                     6.357143   \n",
       "3              0              0                     6.357143   \n",
       "4              0              0                     6.357143   \n",
       "\n",
       "   subject_sincerity_mean  subject_intelligence_mean  subject_fun_mean  \\\n",
       "0                7.714286                   8.071429          6.357143   \n",
       "1                7.714286                   8.071429          6.357143   \n",
       "2                7.714286                   8.071429          6.357143   \n",
       "3                7.714286                   8.071429          6.357143   \n",
       "4                7.714286                   8.071429          6.357143   \n",
       "\n",
       "   subject_ambition_mean  subject_shared_interest_mean  age_difference  \\\n",
       "0               6.785714                      5.285714       -0.213498   \n",
       "1               6.785714                      5.285714        0.113945   \n",
       "2               6.785714                      5.285714       -0.540940   \n",
       "3               6.785714                      5.285714       -0.868383   \n",
       "4               6.785714                      5.285714       -0.540940   \n",
       "\n",
       "   attractiveness_difference  fun_difference  ambition_difference  \\\n",
       "0                  -0.687122       -1.210467            -1.270431   \n",
       "1                  -1.261822       -1.210467            -0.630769   \n",
       "2                   1.036978        0.020660            -1.270431   \n",
       "3                  -0.112422       -0.594903            -0.630769   \n",
       "4                   1.036978        0.636223             0.648555   \n",
       "\n",
       "   shared_interest_difference  \n",
       "0                   -0.087847  \n",
       "1                    1.092457  \n",
       "2                   -0.678000  \n",
       "3                   -0.087847  \n",
       "4                   -1.268152  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1609346"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "data.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13b45e",
   "metadata": {},
   "source": [
    "##### Comment\n",
    "\n",
    "- After dropping more irrelevant data, the dataframe size has further decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b0dd30",
   "metadata": {},
   "source": [
    "Save this pre-processed data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ebcfd30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_file_path = join(data_dir, \"preprocessed.csv\")\n",
    "dataframe_to_csv(data, preprocessed_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f939fc",
   "metadata": {},
   "source": [
    "Below mentioned are the articles, blogs, papers and other resources which we took inspiration from or we think are useful for future use case\n",
    "\n",
    "#### References\n",
    "\n",
    "- [_Getting Started with Data Preprocessing in Python_](https://www.section.io/engineering-education/data-preprocessing-python/)\n",
    "- [_Data Preprocessing in Python_](https://medium.datadriveninvestor.com/data-preprocessing-3cd01eefd438)\n",
    "- [_Data Pre-processing in Python for Beginner_](https://medium.com/data-science-indo/data-preparation-in-python-for-beginner-d3e1e60c03a6)\n",
    "- [_Data Preprocessing using Python_](https://medium.com/@suneet.bhopal/data-preprocessing-using-python-1bfee9268fb3)\n",
    "- [_Data preprocessing for Machine Learning in Python_](https://towardsdatascience.com/data-preprocessing-for-machine-learning-in-python-2d465f83f18c)\n",
    "- [_Data Preprocessing in Machine Learning_](https://www.analytixlabs.co.in/blog/data-preprocessing-in-machine-learning/)\n",
    "- [_Normalization vs Standardization — Quantitative analysis_](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf)\n",
    "- [__]()\n",
    "- [__]()\n",
    "- [__]()\n",
    "- [__]()\n",
    "- [__]()\n",
    "- [__]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682e7ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b33028dfef90447248446bd6a115b2c1f87c179fa7c4ab6e59f7d48c9bbeef80"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
