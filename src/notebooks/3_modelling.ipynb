{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664f2f67-d217-4a9c-b794-fa7fecd115a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # disable warnings\n",
    "\n",
    "from os import getcwd\n",
    "from os.path import join, abspath, pardir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "# sklearn libraries\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer # enable experimental imputer\n",
    "from sklearn.impute import IterativeImputer               # sample imputation\n",
    "from sklearn import preprocessing                         # encoders, transformations\n",
    "from sklearn.model_selection import cross_validate        # cross-validation, model evaluation\n",
    "from sklearn.model_selection import GridSearchCV          # hyper-parameter tuning\n",
    "from sklearn.linear_model import LogisticRegression       # logistic regression model\n",
    "from sklearn.svm import SVC                               # support vector machine model\n",
    "from sklearn.neighbors import KNeighborsClassifier        # k-nearest neighbours model\n",
    "from sklearn.ensemble import GradientBoostingClassifier   # gradient boosting model\n",
    "from sklearn.ensemble import VotingClassifier             # voting ensemble model\n",
    "from sklearn.ensemble import StackingClassifier           # stacking ensemble model\n",
    "\n",
    "# IPython\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83b4df",
   "metadata": {},
   "source": [
    "##### Config settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4894fe-4fc0-4580-b2df-275bbdfb82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = abspath(join(join(getcwd(), pardir), pardir))\n",
    "data_dir = join(parent_dir, \"data\")\n",
    "model_dir = join(parent_dir, \"models\")\n",
    "data_file = join(data_dir, \"preprocessed.csv\")\n",
    "\n",
    "# For IPython\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # To show all output after each cell execution (instead of the last output)\n",
    "\n",
    "# For pandas\n",
    "\n",
    "pd.options.display.max_columns = 200 # display upto 200 columns (instead of default 20)\n",
    "pd.options.display.max_rows = 200 # display upto 200 rows (instead of default 60)\n",
    "\n",
    "# random state\n",
    "__random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627281a6",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46177fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save model as a pickle file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "def load_model(file_path: str):\n",
    "    \"\"\"\n",
    "    Load model from a pickle file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def dataframe_to_csv(df: pd.DataFrame, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save dataframe as .csv file\n",
    "    \"\"\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def get_best_clf(clf, param_grid, X, y, **kwargs):\n",
    "    \"\"\"\n",
    "    Grid Search with stratified splitting and other parameters\n",
    "\n",
    "    Returns best estimator and it's score (F1 score)\n",
    "    \"\"\"\n",
    "\n",
    "    # f1 score rather then accuracy\n",
    "    f1 = make_scorer(f1_score, average='micro')\n",
    "\n",
    "    # stratified split\n",
    "    split_count = 10\n",
    "    kf = StratifiedKFold(n_splits=split_count, random_state=__random_state, shuffle=True)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=clf,\n",
    "        param_grid=param_grid,\n",
    "        scoring=f1,\n",
    "        cv=kf,\n",
    "        n_jobs=-1,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    return grid_search\n",
    "    #return grid_search.best_score_, grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa8062",
   "metadata": {},
   "source": [
    "#### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18ae3627-784c-4550-8dc4-ffd94bcbcbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>match_es</th>\n",
       "      <th>length</th>\n",
       "      <th>numdat_2</th>\n",
       "      <th>race_o_1.0</th>\n",
       "      <th>race_o_4.0</th>\n",
       "      <th>field_cd_2.0</th>\n",
       "      <th>field_cd_3.0</th>\n",
       "      <th>field_cd_4.0</th>\n",
       "      <th>field_cd_6.0</th>\n",
       "      <th>field_cd_7.0</th>\n",
       "      <th>field_cd_9.0</th>\n",
       "      <th>field_cd_11.0</th>\n",
       "      <th>field_cd_15.0</th>\n",
       "      <th>race_2.0</th>\n",
       "      <th>race_3.0</th>\n",
       "      <th>race_6.0</th>\n",
       "      <th>goal_5.0</th>\n",
       "      <th>career_c_1.0</th>\n",
       "      <th>career_c_3.0</th>\n",
       "      <th>career_c_4.0</th>\n",
       "      <th>career_c_5.0</th>\n",
       "      <th>career_c_7.0</th>\n",
       "      <th>career_c_10.0</th>\n",
       "      <th>career_c_11.0</th>\n",
       "      <th>subject_attractiveness_mean</th>\n",
       "      <th>subject_sincerity_mean</th>\n",
       "      <th>subject_intelligence_mean</th>\n",
       "      <th>subject_fun_mean</th>\n",
       "      <th>subject_ambition_mean</th>\n",
       "      <th>subject_shared_interest_mean</th>\n",
       "      <th>age_difference</th>\n",
       "      <th>attractiveness_difference</th>\n",
       "      <th>fun_difference</th>\n",
       "      <th>ambition_difference</th>\n",
       "      <th>shared_interest_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.093734</td>\n",
       "      <td>0.477190</td>\n",
       "      <td>0.405713</td>\n",
       "      <td>0.306851</td>\n",
       "      <td>0.129562</td>\n",
       "      <td>-0.215712</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.213498</td>\n",
       "      <td>-0.687122</td>\n",
       "      <td>-1.210467</td>\n",
       "      <td>-1.270431</td>\n",
       "      <td>-0.087847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.093734</td>\n",
       "      <td>0.477190</td>\n",
       "      <td>0.405713</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>-0.984028</td>\n",
       "      <td>-1.151207</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>0.113945</td>\n",
       "      <td>-1.261822</td>\n",
       "      <td>-1.210467</td>\n",
       "      <td>-0.630769</td>\n",
       "      <td>1.092457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>1.958469</td>\n",
       "      <td>1.053427</td>\n",
       "      <td>1.055676</td>\n",
       "      <td>-0.206682</td>\n",
       "      <td>0.129562</td>\n",
       "      <td>0.252036</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.540940</td>\n",
       "      <td>1.036978</td>\n",
       "      <td>0.020660</td>\n",
       "      <td>-1.270431</td>\n",
       "      <td>-0.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>1.445418</td>\n",
       "      <td>1.629664</td>\n",
       "      <td>1.705638</td>\n",
       "      <td>1.333917</td>\n",
       "      <td>0.686357</td>\n",
       "      <td>-0.215712</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.868383</td>\n",
       "      <td>-0.112422</td>\n",
       "      <td>-0.594903</td>\n",
       "      <td>-0.630769</td>\n",
       "      <td>-0.087847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.606785</td>\n",
       "      <td>-1.251521</td>\n",
       "      <td>-1.544174</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>-0.984028</td>\n",
       "      <td>0.252036</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.785714</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>-0.540940</td>\n",
       "      <td>1.036978</td>\n",
       "      <td>0.636223</td>\n",
       "      <td>0.648555</td>\n",
       "      <td>-1.268152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  pf_o_att  pf_o_sin  pf_o_int  dec_o    attr_o    sinc_o   intel_o  \\\n",
       "0   False        25        25        25  False -0.093734  0.477190  0.405713   \n",
       "1   False        25        20        15  False -0.093734  0.477190  0.405713   \n",
       "2   False        30        15        20   True  1.958469  1.053427  1.055676   \n",
       "3   False        40        20        20  False  1.445418  1.629664  1.705638   \n",
       "4   False        30        10        25  False -0.606785 -1.251521 -1.544174   \n",
       "\n",
       "      fun_o     amb_o    shar_o  imprelig  date  go_out  tvsports  exercise  \\\n",
       "0  0.306851  0.129562 -0.215712         7     4       2         6         7   \n",
       "1 -0.720215 -0.984028 -1.151207         7     4       2         6         7   \n",
       "2 -0.206682  0.129562  0.252036         7     4       2         6         7   \n",
       "3  1.333917  0.686357 -0.215712         7     4       2         6         7   \n",
       "4 -0.720215 -0.984028  0.252036         7     4       2         6         7   \n",
       "\n",
       "   dining  museums  art  hiking  gaming  reading  tv  theater  concerts  \\\n",
       "0       8        6    8       8       4        7   4        7         7   \n",
       "1       8        6    8       8       4        7   4        7         7   \n",
       "2       8        6    8       8       4        7   4        7         7   \n",
       "3       8        6    8       8       4        7   4        7         7   \n",
       "4       8        6    8       8       4        7   4        7         7   \n",
       "\n",
       "   music  attr1_1  sinc1_1  intel1_1  shar1_1  intel3_1  attr  sinc  intel  \\\n",
       "0      7       16       19        16       17         7     7     6      7   \n",
       "1      7       16       19        16       17         7     6     6      6   \n",
       "2      7       16       19        16       17         7     6     8      8   \n",
       "3      7       16       19        16       17         7     7     7      7   \n",
       "4      7       16       19        16       17         7     9     7      8   \n",
       "\n",
       "   fun  match_es  length  numdat_2  race_o_1.0  race_o_4.0  field_cd_2.0  \\\n",
       "0    7         3       1         3           0           0             0   \n",
       "1    5         3       1         3           0           0             0   \n",
       "2    8         3       1         3           0           0             0   \n",
       "3    8         3       1         3           0           0             0   \n",
       "4    8         3       1         3           0           0             0   \n",
       "\n",
       "   field_cd_3.0  field_cd_4.0  field_cd_6.0  field_cd_7.0  field_cd_9.0  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   field_cd_11.0  field_cd_15.0  race_2.0  race_3.0  race_6.0  goal_5.0  \\\n",
       "0              0              0         0         1         0         0   \n",
       "1              0              0         0         1         0         0   \n",
       "2              0              0         0         1         0         0   \n",
       "3              0              0         0         1         0         0   \n",
       "4              0              0         0         1         0         0   \n",
       "\n",
       "   career_c_1.0  career_c_3.0  career_c_4.0  career_c_5.0  career_c_7.0  \\\n",
       "0             0             0             0             1             0   \n",
       "1             0             0             0             1             0   \n",
       "2             0             0             0             1             0   \n",
       "3             0             0             0             1             0   \n",
       "4             0             0             0             1             0   \n",
       "\n",
       "   career_c_10.0  career_c_11.0  subject_attractiveness_mean  \\\n",
       "0              0              0                     6.357143   \n",
       "1              0              0                     6.357143   \n",
       "2              0              0                     6.357143   \n",
       "3              0              0                     6.357143   \n",
       "4              0              0                     6.357143   \n",
       "\n",
       "   subject_sincerity_mean  subject_intelligence_mean  subject_fun_mean  \\\n",
       "0                7.714286                   8.071429          6.357143   \n",
       "1                7.714286                   8.071429          6.357143   \n",
       "2                7.714286                   8.071429          6.357143   \n",
       "3                7.714286                   8.071429          6.357143   \n",
       "4                7.714286                   8.071429          6.357143   \n",
       "\n",
       "   subject_ambition_mean  subject_shared_interest_mean  age_difference  \\\n",
       "0               6.785714                      5.285714       -0.213498   \n",
       "1               6.785714                      5.285714        0.113945   \n",
       "2               6.785714                      5.285714       -0.540940   \n",
       "3               6.785714                      5.285714       -0.868383   \n",
       "4               6.785714                      5.285714       -0.540940   \n",
       "\n",
       "   attractiveness_difference  fun_difference  ambition_difference  \\\n",
       "0                  -0.687122       -1.210467            -1.270431   \n",
       "1                  -1.261822       -1.210467            -0.630769   \n",
       "2                   1.036978        0.020660            -1.270431   \n",
       "3                  -0.112422       -0.594903            -0.630769   \n",
       "4                   1.036978        0.636223             0.648555   \n",
       "\n",
       "   shared_interest_difference  \n",
       "0                   -0.087847  \n",
       "1                    1.092457  \n",
       "2                   -0.678000  \n",
       "3                   -0.087847  \n",
       "4                   -1.268152  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file, encoding= 'ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923cfea",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2ac487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature and target variables\n",
    "features, target = df, df['dec_o']\n",
    "features.drop(['dec_o'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b9893",
   "metadata": {},
   "source": [
    "### 1. Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c959d",
   "metadata": {},
   "source": [
    "#### 1.1. [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85d66cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.0001, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.00026366508987303583, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.0006951927961775605, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.0018329807108324356, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.004832930238571752, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=0.012742749857031334, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=0.03359818286283781, max_iter=10000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.08858667904100823, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=0.23357214690901212, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=0.615848211066026, max_iter=10000, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   2.2s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1.623776739188721, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=4.281332398719396, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=11.288378916846883, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=29.763514416313132, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=78.47599703514607, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=206.913808111479, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=545.5594781168514, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=1438.44988828766, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=3792.690190732246, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=10000.0, max_iter=10000, penalty=l2, solver=lbfgs; total time=   1.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 4.281332398719396, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'max_iter': [10000]\n",
    "}\n",
    "\n",
    "classifier_lr = get_best_clf(\n",
    "    clf=LogisticRegression(random_state=__random_state),\n",
    "    X=features,\n",
    "    y=target,\n",
    "    param_grid=parameters,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "classifier_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb5009d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=4.281332398719396, max_iter=10000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=4.281332398719396, max_iter=10000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=4.281332398719396, max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_logistic_regression = classifier_lr.best_estimator_\n",
    "clf_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e03e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(clf_logistic_regression, join(model_dir, \"clf_logistic_regression.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abb5a6",
   "metadata": {},
   "source": [
    "#### 1.2. [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0883558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.3s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.3s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.4s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.4s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.4s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.5s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.5s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.5s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   4.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   4.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.9s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   3.9s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   4.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   4.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.8s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.9s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   5.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   5.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.4s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.5s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.8s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.8s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.8s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.6s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   4.9s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.4s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.3s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.4s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.5s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.4s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.5s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.4s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   3.6s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.6s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.7s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.9s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.6s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   4.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   3.9s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   4.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.8s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.9s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.8s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   6.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.8s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.4s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   6.1s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   4.1s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.7s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   4.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   6.3s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.8s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.6s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.6s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.6s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.9s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.7s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.7s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.9s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   3.8s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   6.4s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   6.5s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   5.9s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   5.9s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   6.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   6.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   6.3s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   6.6s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   6.6s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   6.8s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.6s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.5s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.4s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.8s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   6.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.7s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.8s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   5.8s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   7.4s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   7.6s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   7.3s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   7.4s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   7.3s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   7.3s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   6.7s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   7.7s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   7.3s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   7.2s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  13.4s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  13.6s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  12.6s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  12.6s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  12.8s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  12.4s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  12.7s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  15.7s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   4.9s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   4.9s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   5.2s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   5.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   5.1s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   5.8s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   4.9s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   5.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  12.6s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=  13.2s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   4.2s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   3.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [1e-4, 1e-3, 1e-2],\n",
    "    'C': [1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "classifier_sv = get_best_clf(\n",
    "    clf=SVC(random_state=__random_state),\n",
    "    X=features,\n",
    "    y=target,\n",
    "    param_grid=parameters,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "classifier_sv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9420d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, gamma=0.0001, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=0.0001, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, gamma=0.0001, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc = classifier_sv.best_estimator_\n",
    "clf_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b91326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(clf_svc, join(model_dir, \"clf_svc.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ff551",
   "metadata": {},
   "source": [
    "#### 1.3. [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee1862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=minkowski, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=minkowski, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=11, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=11, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=19, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=19, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=29, weights=uniform; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=29, weights=distance; total time=   0.1s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.4s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=11, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.3s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=11, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=19, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=19, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.5s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.4s\n",
      "[CV] END ..metric=manhattan, n_neighbors=29, weights=uniform; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.4s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.3s\n",
      "[CV] END .metric=manhattan, n_neighbors=29, weights=distance; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 29, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_neighbors': [5, 11, 19, 29],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "classifier_kn = get_best_clf(\n",
    "    clf=KNeighborsClassifier(),\n",
    "    X=features,\n",
    "    y=target,\n",
    "    param_grid=parameters,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "classifier_kn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ca18a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=29)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=29)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='manhattan', n_neighbors=29)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn = classifier_kn.best_estimator_\n",
    "clf_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13afafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(clf_knn, join(model_dir, \"clf_knn.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803e1ca",
   "metadata": {},
   "source": [
    "### 2. [Ensemble models](https://scikit-learn.org/stable/modules/ensemble.html#ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce0a76d",
   "metadata": {},
   "source": [
    "#### 2.1. [Gradient Boost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa7bff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=200; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=3, max_features=log2, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=200; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=4, max_features=log2, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=200; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/machine_learning/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=deviance, max_depth=5, max_features=log2, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=3, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=sqrt, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=4, max_features=log2, n_estimators=300; total time=   1.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=200; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.6s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.4s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=sqrt, n_estimators=300; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.2s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.9s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.8s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.5s\n",
      "[CV] END learning_rate=0.05, loss=exponential, max_depth=5, max_features=log2, n_estimators=300; total time=   1.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'learning_rate': [0.05],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "classifier_gb = get_best_clf(\n",
    "    clf=GradientBoostingClassifier(random_state=__random_state),\n",
    "    X=features,\n",
    "    y=target,\n",
    "    param_grid=parameters,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "classifier_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd3b526f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.05, loss=&#x27;deviance&#x27;, max_depth=5,\n",
       "                           max_features=&#x27;sqrt&#x27;, n_estimators=300,\n",
       "                           random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.05, loss=&#x27;deviance&#x27;, max_depth=5,\n",
       "                           max_features=&#x27;sqrt&#x27;, n_estimators=300,\n",
       "                           random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.05, loss='deviance', max_depth=5,\n",
       "                           max_features='sqrt', n_estimators=300,\n",
       "                           random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gb = classifier_gb.best_estimator_\n",
    "clf_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8062f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(clf_gb, join(model_dir, \"clf_gb.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68621907",
   "metadata": {},
   "source": [
    "#### 2.2. [Voting Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)\n",
    "\n",
    "Let's combine all classifiers and train a voting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae05dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lr', clf_logistic_regression), # logistic regression\n",
    "    ('sv', clf_svc), # svc\n",
    "    ('kn', clf_knn), # knn\n",
    "    ('gb', clf_gb) # gradient boosting\n",
    "]\n",
    "\n",
    "# voting classifier\n",
    "clf_voting = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caef4f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=4.281332398719396,\n",
       "                                                 max_iter=10000,\n",
       "                                                 random_state=0)),\n",
       "                             (&#x27;sv&#x27;, SVC(C=100, gamma=0.0001, random_state=0)),\n",
       "                             (&#x27;kn&#x27;,\n",
       "                              KNeighborsClassifier(metric=&#x27;manhattan&#x27;,\n",
       "                                                   n_neighbors=29)),\n",
       "                             (&#x27;gb&#x27;,\n",
       "                              GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                                         loss=&#x27;deviance&#x27;,\n",
       "                                                         max_depth=5,\n",
       "                                                         max_features=&#x27;sqrt&#x27;,\n",
       "                                                         n_estimators=300,\n",
       "                                                         random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=4.281332398719396,\n",
       "                                                 max_iter=10000,\n",
       "                                                 random_state=0)),\n",
       "                             (&#x27;sv&#x27;, SVC(C=100, gamma=0.0001, random_state=0)),\n",
       "                             (&#x27;kn&#x27;,\n",
       "                              KNeighborsClassifier(metric=&#x27;manhattan&#x27;,\n",
       "                                                   n_neighbors=29)),\n",
       "                             (&#x27;gb&#x27;,\n",
       "                              GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                                         loss=&#x27;deviance&#x27;,\n",
       "                                                         max_depth=5,\n",
       "                                                         max_features=&#x27;sqrt&#x27;,\n",
       "                                                         n_estimators=300,\n",
       "                                                         random_state=0))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=4.281332398719396, max_iter=10000, random_state=0)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>sv</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=0.0001, random_state=0)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>kn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=29)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.05, loss=&#x27;deviance&#x27;, max_depth=5,\n",
       "                           max_features=&#x27;sqrt&#x27;, n_estimators=300,\n",
       "                           random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=4.281332398719396,\n",
       "                                                 max_iter=10000,\n",
       "                                                 random_state=0)),\n",
       "                             ('sv', SVC(C=100, gamma=0.0001, random_state=0)),\n",
       "                             ('kn',\n",
       "                              KNeighborsClassifier(metric='manhattan',\n",
       "                                                   n_neighbors=29)),\n",
       "                             ('gb',\n",
       "                              GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                                         loss='deviance',\n",
       "                                                         max_depth=5,\n",
       "                                                         max_features='sqrt',\n",
       "                                                         n_estimators=300,\n",
       "                                                         random_state=0))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=4.281332398719396,\n",
       "                                                 max_iter=10000,\n",
       "                                                 random_state=0)),\n",
       "                             (&#x27;sv&#x27;, SVC(C=100, gamma=0.0001, random_state=0)),\n",
       "                             (&#x27;kn&#x27;,\n",
       "                              KNeighborsClassifier(metric=&#x27;manhattan&#x27;,\n",
       "                                                   n_neighbors=29)),\n",
       "                             (&#x27;gb&#x27;,\n",
       "                              GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                                         loss=&#x27;deviance&#x27;,\n",
       "                                                         max_depth=5,\n",
       "                                                         max_features=&#x27;sqrt&#x27;,\n",
       "                                                         n_estimators=300,\n",
       "                                                         random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=4.281332398719396,\n",
       "                                                 max_iter=10000,\n",
       "                                                 random_state=0)),\n",
       "                             (&#x27;sv&#x27;, SVC(C=100, gamma=0.0001, random_state=0)),\n",
       "                             (&#x27;kn&#x27;,\n",
       "                              KNeighborsClassifier(metric=&#x27;manhattan&#x27;,\n",
       "                                                   n_neighbors=29)),\n",
       "                             (&#x27;gb&#x27;,\n",
       "                              GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                                         loss=&#x27;deviance&#x27;,\n",
       "                                                         max_depth=5,\n",
       "                                                         max_features=&#x27;sqrt&#x27;,\n",
       "                                                         n_estimators=300,\n",
       "                                                         random_state=0))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=4.281332398719396, max_iter=10000, random_state=0)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>sv</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=0.0001, random_state=0)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>kn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=29)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.05, loss=&#x27;deviance&#x27;, max_depth=5,\n",
       "                           max_features=&#x27;sqrt&#x27;, n_estimators=300,\n",
       "                           random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=4.281332398719396,\n",
       "                                                 max_iter=10000,\n",
       "                                                 random_state=0)),\n",
       "                             ('sv', SVC(C=100, gamma=0.0001, random_state=0)),\n",
       "                             ('kn',\n",
       "                              KNeighborsClassifier(metric='manhattan',\n",
       "                                                   n_neighbors=29)),\n",
       "                             ('gb',\n",
       "                              GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                                         loss='deviance',\n",
       "                                                         max_depth=5,\n",
       "                                                         max_features='sqrt',\n",
       "                                                         n_estimators=300,\n",
       "                                                         random_state=0))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_voting.fit(features, target)\n",
    "clf_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9f4cf30",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VotingClassifier' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/mohammadzainabbas/Masters/UPC/Machine Learning/Speed-Dating-ML/src/notebooks/3_modelling.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mohammadzainabbas/Masters/UPC/Machine%20Learning/Speed-Dating-ML/src/notebooks/3_modelling.ipynb#ch0000115?line=0'>1</a>\u001b[0m clf_voting \u001b[39m=\u001b[39m clf_voting\u001b[39m.\u001b[39;49mbest_estimator_\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VotingClassifier' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "clf_voting = clf_voting.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1831ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(clf_voting, join(model_dir, \"clf_voting.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedfcf9e",
   "metadata": {},
   "source": [
    "#### 2.3. [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8bb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking classifier\n",
    "clf_stacking = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "clf_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_stacking.fit(features, target)\n",
    "clf_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325be8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_stacking = clf_stacking.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(clf_stacking, join(model_dir, \"clf_stacking.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b33028dfef90447248446bd6a115b2c1f87c179fa7c4ab6e59f7d48c9bbeef80"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
