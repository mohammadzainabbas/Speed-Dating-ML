{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f2f67-d217-4a9c-b794-fa7fecd115a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # disable warnings\n",
    "\n",
    "from os import getcwd\n",
    "from os.path import join, abspath, pardir, exists\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle, json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "# scipy\n",
    "from scipy.stats import ttest_ind, chi2_contingency, boxcox, skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.impute import KNNImputer, SimpleImputer, MissingIndicator\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.pipeline import FeatureUnion, make_pipeline, Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import make_column_selector, make_column_transformer, make_column_transformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer # enable experimental imputer\n",
    "from sklearn.impute import IterativeImputer               # sample imputation\n",
    "from sklearn import preprocessing                         # encoders, transformations\n",
    "from sklearn.model_selection import cross_validate        # cross-validation, model evaluation\n",
    "from sklearn.model_selection import GridSearchCV          # hyper-parameter tuning\n",
    "from sklearn.linear_model import LogisticRegression       # logistic regression model\n",
    "from sklearn.svm import SVC                               # support vector machine model\n",
    "from sklearn.neighbors import KNeighborsClassifier        # k-nearest neighbours model\n",
    "from sklearn.ensemble import GradientBoostingClassifier   # gradient boosting model\n",
    "from sklearn.ensemble import VotingClassifier             # voting ensemble model\n",
    "from sklearn.ensemble import StackingClassifier           # stacking ensemble model\n",
    "\n",
    "\n",
    "# statsmodel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# IPython\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83b4df",
   "metadata": {},
   "source": [
    "##### Config settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4894fe-4fc0-4580-b2df-275bbdfb82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = abspath(join(join(getcwd(), pardir), pardir))\n",
    "data_dir = join(parent_dir, \"data\")\n",
    "model_dir = join(parent_dir, \"models\")\n",
    "data_file = join(data_dir, \"preprocessed.csv\")\n",
    "\n",
    "# For IPython\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # To show all output after each cell execution (instead of the last output)\n",
    "\n",
    "# For pandas\n",
    "\n",
    "pd.options.display.max_columns = 200 # display upto 200 columns (instead of default 20)\n",
    "pd.options.display.max_rows = 200 # display upto 200 rows (instead of default 60)\n",
    "\n",
    "# random state\n",
    "__random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627281a6",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46177fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save model as a pickle file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "def load_model(file_path: str):\n",
    "    \"\"\"\n",
    "    Load model from a pickle file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def dataframe_to_csv(df: pd.DataFrame, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save dataframe as .csv file\n",
    "    \"\"\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def get_best_clf(clf, param_grid, X, y, **kwargs):\n",
    "\n",
    "    # f1 score rather then accuracy\n",
    "    f1 = make_scorer(f1_score, average='micro')\n",
    "\n",
    "    # stratified split\n",
    "    split_count = 10\n",
    "    kf = StratifiedKFold(n_splits=split_count,random_state=RandomState,shuffle=True)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=clf,\n",
    "        param_grid=grid_param,\n",
    "        scoring=f1,\n",
    "        cv=kf,\n",
    "        n_jobs=-1,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    gd_sr.fit(X, y)\n",
    "    return gd_sr.best_score_,gd_sr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa8062",
   "metadata": {},
   "source": [
    "#### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae3627-784c-4550-8dc4-ffd94bcbcbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file, encoding= 'ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923cfea",
   "metadata": {},
   "source": [
    "### Modelling\n",
    "\n",
    "#### 1. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature and target variables\n",
    "features, target = df, df['dec_o']\n",
    "features.drop(['dec_o'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c959d",
   "metadata": {},
   "source": [
    "1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'max_iter': [10000]\n",
    "}\n",
    "classifier_lr = LogisticRegression(random_state=__random_state)\n",
    "classifier_lr = GridSearchCV(\n",
    "    estimator=classifier_lr,\n",
    "    param_grid=parameters,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "classifier_lr.fit(features, target)\n",
    "classifier_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logistic_regression = LogisticRegression(\n",
    "    random_state=__random_state,\n",
    "    penalty=classifier_lr.best_params_['penalty'],\n",
    "    solver=classifier_lr.best_params_['solver'],\n",
    "    C=classifier_lr.best_params_['C'],\n",
    "    max_iter=classifier_lr.best_params_['max_iter']\n",
    ")\n",
    "clf_logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abb5a6",
   "metadata": {},
   "source": [
    "2. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [1e-4, 1e-3, 1e-2],\n",
    "    'C': [1, 10, 100, 1000]\n",
    "}\n",
    "classifier_sv = SVC(random_state=__random_state)\n",
    "classifier_sv = GridSearchCV(\n",
    "    estimator=classifier_sv,\n",
    "    param_grid=parameters,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "classifier_sv.fit(features, target)\n",
    "classifier_sv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9420d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = SVC(\n",
    "    random_state=__random_state,\n",
    "    kernel=classifier_sv.best_params_['kernel'],\n",
    "    gamma=classifier_sv.best_params_['gamma'],\n",
    "    C=classifier_sv.best_params_['C']\n",
    ")\n",
    "clf_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ff551",
   "metadata": {},
   "source": [
    "3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_neighbors': [5, 11, 19, 29],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "}\n",
    "classifier_kn = KNeighborsClassifier()\n",
    "classifier_kn = GridSearchCV(\n",
    "    estimator=classifier_kn,\n",
    "    param_grid=parameters,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "classifier_kn.fit(features, target)\n",
    "classifier_kn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca18a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier(\n",
    "    n_neighbors=classifier_kn.best_params_['n_neighbors'],\n",
    "    weights=classifier_kn.best_params_['weights'],\n",
    "    metric=classifier_kn.best_params_['metric']\n",
    ")\n",
    "clf_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803e1ca",
   "metadata": {},
   "source": [
    "#### 2. Ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce0a76d",
   "metadata": {},
   "source": [
    "1. Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7bff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'learning_rate': [0.05],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "classifier_gb = GradientBoostingClassifier(random_state=__random_state)\n",
    "classifier_gb = GridSearchCV(\n",
    "    estimator=classifier_gb,\n",
    "    param_grid=parameters,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "classifier_gb.fit(features, target)\n",
    "classifier_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gb = GradientBoostingClassifier(\n",
    "    random_state=__random_state,\n",
    "    loss=classifier_gb.best_params_['loss'],\n",
    "    learning_rate=classifier_gb.best_params_['learning_rate'],\n",
    "    n_estimators=classifier_gb.best_params_['n_estimators'],\n",
    "    max_depth=classifier_gb.best_params_['max_depth'],\n",
    "    max_features=classifier_gb.best_params_['max_features']\n",
    ")\n",
    "clf_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68621907",
   "metadata": {},
   "source": [
    "2. Voting Classifier\n",
    "\n",
    "Let's combine all classifiers and train a voting and stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lr', clf_logistic_regression), # logistic regression\n",
    "    ('sv', clf_svc), # svc\n",
    "    ('kn', clf_knn), # knn\n",
    "    ('gb', clf_gb) # gradient boosting\n",
    "]\n",
    "\n",
    "# voting classifier\n",
    "clf_voting = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting='hard'\n",
    ")\n",
    "clf_voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedfcf9e",
   "metadata": {},
   "source": [
    "3. Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8bb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking classifier\n",
    "clf_stacking = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "clf_stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd94b75",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b33028dfef90447248446bd6a115b2c1f87c179fa7c4ab6e59f7d48c9bbeef80"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
